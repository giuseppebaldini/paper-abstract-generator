{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {},
   "source": [
    "# Conditional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31881b08-e995-4211-81f7-2c1f89835fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data = parse_file('data/anthology+abstracts.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9ee3fa-f7a0-48fb-919b-a866b9bf053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lieberman-etal-1965-automatic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bib_data.entries.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeafa7ec-d2c0-42ad-9720-02b401c6ffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(bib_data.entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8568f11e-dcb1-4551-8a41-9bf8b654af31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1965'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_data.entries['lieberman-etal-1965-automatic'].fields['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a59e7e-50eb-45dd-8607-d219321259c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract)\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b9ad1b-0b2e-4210-9e99-94c6724d2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate stop words\n",
    "def tokenize_input(input):\n",
    "    # make everything lowercase\n",
    "    input = input.lower()\n",
    "\n",
    "    # use tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # filter out stopwords\n",
    "    final = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    \n",
    "    # end result in final\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cc7a9-6a06-4759-9314-d1a5dcd6b0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2016,2022):        \n",
    "        with open('data/datasets/abstracts_%s.txt' %year) as abstr:\n",
    "            lines = abstr.readlines()\n",
    "            processed = tokenize_input(lines[0])\n",
    "            \n",
    "            # create individual year files\n",
    "            y = open('data/datasets/%s.txt' %year, 'a')\n",
    "            y.write(processed)\n",
    "            \n",
    "            # create all years file\n",
    "            a = open('data/datasets/all.txt', 'a')\n",
    "            a.write(processed)\n",
    "            \n",
    "            y.close()\n",
    "            a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db46f9c-3081-4472-8cc9-cc62b1f81b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract + '\\n')\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d574e6c-5be4-4932-9578-0789473d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2016.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "933158cf-9c36-40e3-b7c1-6ee45e32f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = [remove_stopwords(a) for a in abstracts]\n",
    "lowercase = [a.lower() for a in trimmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d10edbc-e5bf-45c4-afbf-493cbd1e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized = [tokenizer.tokenize(a) for a in lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "660af61f-3939-4219-96e5-9d51bb5a6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokenized abstracts\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "550c3d2a-f342-4a91-a916-94cac0fef847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'article',\n",
       " 'proposes',\n",
       " 'universal',\n",
       " 'dependency',\n",
       " 'annotation',\n",
       " 'scheme',\n",
       " 'mandarin',\n",
       " 'chinese',\n",
       " 'including',\n",
       " 'pos',\n",
       " 'tags',\n",
       " 'dependency',\n",
       " 'analysis',\n",
       " 'we',\n",
       " 'identify',\n",
       " 'cases',\n",
       " 'idiosyncrasy',\n",
       " 'mandarin',\n",
       " 'chinese',\n",
       " 'difficult',\n",
       " 'fit',\n",
       " 'current',\n",
       " 'schema',\n",
       " 'mainly',\n",
       " 'based',\n",
       " 'descriptions',\n",
       " 'indo',\n",
       " 'european',\n",
       " 'languages',\n",
       " 'we',\n",
       " 'discuss',\n",
       " 'differences',\n",
       " 'scheme',\n",
       " 'stanford',\n",
       " 'chinese',\n",
       " 'dependencies',\n",
       " 'chinese',\n",
       " 'dependency',\n",
       " 'treebank']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tokenized abstract\n",
    "tokenized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "21bf0748-9359-435f-93ea-8a366e643728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation'"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single word\n",
    "tokenized[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "33379870-94d5-4d2e-a786-78040d51c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # could use itertools for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "98d0da96-277b-4ae5-8dce-330251f14937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162958"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07f3b1-3d1d-4a18-98cf-45261a7b72d0",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "5ba0dd7d-aaad-42b4-880b-f01c4dccbd78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newly'"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = Dictionary(tokenized)\n",
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13614"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "f22a8a06-e8a2-4e66-8d5d-19ba5922eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim dict at 1000 tokens\n",
    "dct.filter_extremes(no_below=1, no_above=0.1, keep_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "4f9b1d0e-358c-4ac6-b688-e51101bc391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e9e43733-6f7e-41d6-a7e1-1c264532dc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layers'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1000 unique tokens: ['0', '4', 'according', 'annotating', 'case']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(text) for text in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ff58d-7c9b-450a-bf83-518d70de82d3",
   "metadata": {},
   "source": [
    "### LDA (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9590b34-fe3b-45c5-925f-cc8bb31c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, num_topics=10, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "565d6120-5b44-45e0-ad8c-f3a77cbba6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"la\" + 0.020*\"des\" + 0.016*\"les\" + 0.016*\"l\" + 0.015*\"d\" + 0.012*\"r\" + 0.011*\"une\" + 0.008*\"le\" + 0.008*\"es\" + 0.007*\"du\"'),\n",
       " (1,\n",
       "  '0.010*\"d\" + 0.009*\"sense\" + 0.008*\"l\" + 0.007*\"le\" + 0.007*\"wordnet\" + 0.006*\"terms\" + 0.006*\"lexicon\" + 0.006*\"les\" + 0.006*\"categories\" + 0.005*\"la\"'),\n",
       " (2,\n",
       "  '0.014*\"les\" + 0.013*\"d\" + 0.011*\"nlp\" + 0.009*\"sentence\" + 0.007*\"des\" + 0.007*\"en\" + 0.007*\"alignment\" + 0.006*\"une\" + 0.006*\"time\" + 0.006*\"extraction\"'),\n",
       " (3,\n",
       "  '0.010*\"sentiment\" + 0.009*\"chinese\" + 0.008*\"detection\" + 0.007*\"cross\" + 0.006*\"target\" + 0.006*\"tweets\" + 0.005*\"event\" + 0.005*\"arabic\" + 0.005*\"existing\" + 0.005*\"provide\"'),\n",
       " (4,\n",
       "  '0.010*\"questions\" + 0.009*\"domain\" + 0.009*\"sentiment\" + 0.009*\"neural\" + 0.008*\"event\" + 0.007*\"document\" + 0.007*\"search\" + 0.006*\"online\" + 0.006*\"documents\" + 0.006*\"web\"'),\n",
       " (5,\n",
       "  '0.013*\"d\" + 0.012*\"les\" + 0.011*\"des\" + 0.010*\"la\" + 0.008*\"entity\" + 0.008*\"named\" + 0.007*\"le\" + 0.007*\"en\" + 0.007*\"c\" + 0.007*\"dans\"'),\n",
       " (6,\n",
       "  '0.010*\"d\" + 0.009*\"wordnet\" + 0.007*\"synsets\" + 0.006*\"domain\" + 0.006*\"structure\" + 0.006*\"des\" + 0.006*\"problem\" + 0.005*\"user\" + 0.005*\"process\" + 0.005*\"open\"'),\n",
       " (7,\n",
       "  '0.009*\"d\" + 0.009*\"des\" + 0.008*\"discourse\" + 0.008*\"la\" + 0.007*\"dialogue\" + 0.007*\"en\" + 0.006*\"tool\" + 0.006*\"japanese\" + 0.005*\"le\" + 0.005*\"les\"'),\n",
       " (8,\n",
       "  '0.015*\"la\" + 0.015*\"d\" + 0.009*\"l\" + 0.009*\"le\" + 0.009*\"dans\" + 0.008*\"des\" + 0.008*\"les\" + 0.007*\"nous\" + 0.006*\"neural\" + 0.005*\"r\"'),\n",
       " (9,\n",
       "  '0.009*\"classification\" + 0.007*\"domain\" + 0.006*\"sentence\" + 0.006*\"relations\" + 0.005*\"terms\" + 0.005*\"pairs\" + 0.005*\"neural\" + 0.005*\"i\" + 0.005*\"similarity\" + 0.005*\"context\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac0bb7-53be-4860-bfaf-9856cc786cdd",
   "metadata": {},
   "source": [
    "### Doc2Vec (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c09238-591e-4bd0-9bca-02827842fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a207060-e36c-43e3-96b5-d23a75d8a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(documents, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c389e-0e7b-4075-a25b-35fd0c3ec7c3",
   "metadata": {},
   "source": [
    "### LSA (ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a23f290-e1c1-4802-a2d2-78c99c312940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=10, decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "320931a9-1e16-4890-8fbc-dcd1311646c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.403*\"d\" + 0.369*\"la\" + 0.342*\"les\" + 0.332*\"des\" + 0.258*\"l\" + 0.232*\"le\" + 0.189*\"r\" + 0.181*\"en\" + 0.180*\"une\" + 0.177*\"dans\"'),\n",
       " (1,\n",
       "  '-0.184*\"sentiment\" + -0.162*\"neural\" + -0.135*\"classification\" + -0.129*\"domain\" + -0.123*\"sentence\" + -0.116*\"nlp\" + -0.106*\"relations\" + -0.102*\"network\" + -0.100*\"sentences\" + -0.098*\"0\"'),\n",
       " (2,\n",
       "  '-0.835*\"sentiment\" + -0.134*\"chinese\" + -0.133*\"lexicon\" + 0.114*\"relations\" + -0.113*\"tutorial\" + -0.109*\"arabic\" + -0.082*\"tools\" + -0.077*\"lexicons\" + -0.076*\"social\" + -0.072*\"polarity\"'),\n",
       " (3,\n",
       "  '-0.536*\"neural\" + -0.280*\"network\" + -0.216*\"attention\" + -0.162*\"sentence\" + -0.157*\"networks\" + 0.139*\"lexicon\" + -0.133*\"al\" + 0.130*\"arabic\" + 0.112*\"wordnet\" + 0.112*\"tools\"'),\n",
       " (4,\n",
       "  '0.616*\"d\" + -0.480*\"les\" + -0.315*\"des\" + 0.174*\"nous\" + 0.166*\"une\" + -0.139*\"la\" + 0.115*\"sur\" + 0.114*\"l\" + -0.103*\"que\" + 0.100*\"article\"'),\n",
       " (5,\n",
       "  '-0.680*\"la\" + 0.497*\"les\" + 0.283*\"d\" + -0.188*\"le\" + -0.130*\"parole\" + -0.127*\"du\" + 0.112*\"sont\" + -0.109*\"l\" + -0.101*\"dans\" + 0.089*\"nous\"'),\n",
       " (6,\n",
       "  '0.457*\"entity\" + 0.312*\"named\" + -0.219*\"sentence\" + 0.197*\"questions\" + 0.188*\"classification\" + 0.184*\"entities\" + 0.183*\"question\" + 0.146*\"recognition\" + -0.144*\"parallel\" + -0.139*\"syntactic\"'),\n",
       " (7,\n",
       "  '-0.448*\"relations\" + -0.260*\"relation\" + 0.222*\"nlp\" + -0.215*\"classification\" + -0.190*\"wordnet\" + -0.189*\"sense\" + -0.176*\"discourse\" + 0.171*\"arabic\" + 0.127*\"users\" + 0.125*\"user\"'),\n",
       " (8,\n",
       "  '-0.403*\"arabic\" + 0.293*\"nlp\" + -0.261*\"domain\" + -0.239*\"lexicon\" + -0.150*\"0\" + -0.142*\"terms\" + 0.130*\"applications\" + -0.129*\"entity\" + -0.124*\"named\" + 0.119*\"chinese\"'),\n",
       " (9,\n",
       "  '0.346*\"sentence\" + -0.277*\"arabic\" + -0.260*\"nlp\" + -0.236*\"al\" + 0.216*\"sentences\" + -0.211*\"wordnet\" + 0.209*\"domain\" + -0.172*\"neural\" + 0.159*\"parallel\" + 0.126*\"entity\"')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36da2234-e893-4f90-82e3-f45cae8734df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arabic', -0.4034451193802862),\n",
       " ('nlp', 0.2934368452795288),\n",
       " ('domain', -0.26109461691817776),\n",
       " ('lexicon', -0.23909680583390266),\n",
       " ('0', -0.15035794497924815),\n",
       " ('terms', -0.14177416563946646),\n",
       " ('applications', 0.12972419053767675),\n",
       " ('entity', -0.12925842883420413),\n",
       " ('named', -0.12435832177626265),\n",
       " ('chinese', 0.11888435328098947),\n",
       " ('lexicons', -0.11743091268468898),\n",
       " ('mt', -0.11389644348425909),\n",
       " ('dependency', 0.11088695819433446),\n",
       " ('relations', 0.11038807326066608),\n",
       " ('representation', 0.10541354821936533),\n",
       " ('tools', 0.10074511719805448),\n",
       " ('question', 0.0999808924339344),\n",
       " ('users', 0.09888998611455983),\n",
       " ('inference', 0.09794536455095064),\n",
       " ('translations', -0.09588008681166743)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topic(8, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6ba013f-0207-4346-a922-8f83271b4a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x2a27f02ec88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e86a9f8-69a5-4484-953b-a5374b71eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation = lsi.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "530f6a7c-9677-47e2-a782-2033157476f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.projection.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27085349-f8e1-412d-b6c1-d662b59af280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_representation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12a05e-1a97-4ba1-a769-da71050edff8",
   "metadata": {},
   "source": [
    "## LSTM from scratch #1 (OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755975e-4bdf-4767-b0ab-f4b7b26e827c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "7cd53e27-9a22-4b32-9971-829f4a8006d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, words, dictionary, sequence_length=5): # TODO: incorporate dictionary\n",
    "        self.words = words[:2000]\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f6b2f-bb3f-453c-a457-4fdab09a129e",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "e14c26a8-9296-455d-ba81-3aeee89718a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset, lstm_size=256, emdedding_dim=256, num_layers=2, dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding_dim = emdedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.sequence_length = dataset.sequence_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, self.sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, self.sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1bb67-4d3b-4b7d-aa9d-4579ba6e9f56",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "b66873a3-72f0-48c0-ba89-662bd4e9541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(dataset, model, batch_size=128, max_epochs=3):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 50 == 0:\n",
    "                print({ 'Epoch': epoch, 'Batch': batch, 'Loss': loss.item() })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09ed4a-bc3d-4a6a-8da9-046cd8fe6d38",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "6b85efe7-4860-4b4a-ad6e-69fcf567b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(dataset, model, text, next_words=100):\n",
    "    output = text.split(' ')\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in output[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        \n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        output.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "b65525b5-f993-400d-a16b-7dacd946a2e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0, 'Batch': 0, 'Loss': 6.910434722900391}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-802-eafc12205a01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-800-4e2cd26930fb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, model, batch_size, max_epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mstate_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = 'in this paper we propose'\n",
    "\n",
    "dataset = Dataset(words, dct, sequence_length=len(text.split(' ')))\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "803f9e7e-d3b2-4b2d-bde2-0471036ab018",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10,  9,  7,  1, 62]])\n",
      "299\n",
      "tensor([[  9,   7,   1,  62, 299]])\n",
      "674\n",
      "tensor([[  7,   1,  62, 299, 674]])\n",
      "209\n",
      "tensor([[  1,  62, 299, 674, 209]])\n",
      "316\n",
      "tensor([[ 62, 299, 674, 209, 316]])\n",
      "135\n",
      "tensor([[299, 674, 209, 316, 135]])\n",
      "667\n",
      "tensor([[674, 209, 316, 135, 667]])\n",
      "598\n",
      "tensor([[209, 316, 135, 667, 598]])\n",
      "871\n",
      "tensor([[316, 135, 667, 598, 871]])\n",
      "14\n",
      "tensor([[135, 667, 598, 871,  14]])\n",
      "254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'in this paper we propose good 04 current sources pos an both vocalization set generated'"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(dataset, model, text=text, next_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "70f9547f-259b-4e93-ab98-f2b56c9024aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'propose'"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index_to_word[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a7e92-dc29-4f8a-82c7-aa5038838508",
   "metadata": {},
   "source": [
    "## LSTM from scratch #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "3d1d607d-c1ae-42cc-a230-22d7553275d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # Number of samples per time step\n",
    "        self.batch_size = 1\n",
    "\n",
    "        # Dimension of weight vectors\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Dimension of embedded tensor\n",
    "        self.embedding_dim = 2\n",
    "\n",
    "        # Vocabulary size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Number of time steps\n",
    "        self.sequence_len = 1\n",
    "    \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_dim, padding_idx=0)\n",
    "    \n",
    "        # Initialize LSTM Cell\n",
    "        self.lstm_cell = nn.LSTMCell(self.embedding_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.tensor(x).to(device).long()\n",
    "\n",
    "        # batch_size x hidden_size\n",
    "        hidden_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cell_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        hidden_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cell_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "        # weights initialization\n",
    "        torch.nn.init.xavier_normal_(hidden_state)\n",
    "        torch.nn.init.xavier_normal_(cell_state)\n",
    "        torch.nn.init.xavier_normal_(hidden_state_2)\n",
    "        torch.nn.init.xavier_normal_(cell_state_2)\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        # Prepare the shape for LSTMCell\n",
    "        out = out.view(self.sequence_len, x.size(0), -1)\n",
    "    \n",
    "        # Unfolding LSTM\n",
    "        # Last hidden_state will be used to feed the fully connected neural net\n",
    "        for i in range(self.sequence_len):\n",
    "            hidden_state, cell_state = self.lstm_cell_1(out[i], (hidden_state, cell_state))\n",
    "            hidden_state_2, cell_state_2 = self.lstm_cell_2(hidden_state, (hidden_state_2, cell_state_2))\n",
    "            \n",
    "        # Last hidden state is passed through a fully connected neural net\n",
    "        out = self.fully_connected(hidden_state_2)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "a2323509-77dc-4263-9023-3294a35cb114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def forward(self, x):\n",
    "\n",
    "#     # batch_size x hidden_size\n",
    "#     hidden_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     cell_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     hidden_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     cell_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "#     # weights initialization\n",
    "#     torch.nn.init.xavier_normal_(hidden_state)\n",
    "#     torch.nn.init.xavier_normal_(cell_state)\n",
    "#     torch.nn.init.xavier_normal_(hidden_state_2)\n",
    "#     torch.nn.init.xavier_normal_(cell_state_2)\n",
    "\n",
    "#     # From idx to embedding\n",
    "#     out = self.embedding(x)\n",
    "\n",
    "#     # Prepare the shape for LSTMCell\n",
    "#     out = out.view(self.sequence_len, x.size(0), -1)\n",
    "    \n",
    "#     # Unfolding LSTM\n",
    "#     # Last hidden_state will be used to feed the fully connected neural net\n",
    "#     for i in range(self.sequence_len):\n",
    "#         hidden_state, cell_state = self.lstm_cell_1(out[i], (hidden_state, cell_state))\n",
    "#         hidden_state_2, cell_state_2 = self.lstm_cell_2(hidden_state, (hidden_state_2, cell_state_2))\n",
    "        \n",
    "#     # Last hidden state is passed through a fully connected neural net\n",
    "#     out = self.fully_connected(hidden_state_2)\n",
    "    \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "20a2f682-f276-4cca-aa92-de763f48d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size=5, hidden_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "24c15cfb-f954-4c17-80a6-27157cb88faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(5, 2, padding_idx=0)\n",
       "  (lstm_cell): LSTMCell(2, 10)\n",
       ")"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "ef4cd38e-8adb-4877-bd0f-b9354dac20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "dfa78d34-2235-40d6-b425-81b1da0616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(model.batch_size, model.sequence_len, model.input_size)\n",
    "hidden_state = torch.randn(n_layers, model.batch_size, model.hidden_dim)\n",
    "cell_state = torch.randn(n_layers, model.batch_size, model.hidden_dim)\n",
    "hidden = (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "71767259-07dd-437f-b87f-c1369b12d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "d90aaa5b-bbf1-4404-aa06-c37b263b83d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "1cdf3db8-b3d1-4460-8468-311257db0d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "cbd16d08-584a-496e-8c04-b2e1b120f44e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index -2 out of table with 4 rows. at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-0i480kur\\aten\\src\\TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-496-1c57ef84e75d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-487-933505bd3096>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# From idx to embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Prepare the shape for LSTMCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m         return F.embedding(\n\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index out of range: Tried to access index -2 out of table with 4 rows. at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-0i480kur\\aten\\src\\TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": [
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "35fe0c86-650f-45d8-a5c2-df6fc6fb9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim)\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 1\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b6124d9a-b573-4479-bb23-06228faacd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2030, -1.1694,  0.6893,  0.0536, -0.6025, -0.4385,  0.3766,\n",
       "            1.4402, -0.6188, -0.2681]]]),\n",
       " tensor([[[-1.1527, -0.6507,  0.7959, -2.2271, -0.5886, -1.1727,  0.9629,\n",
       "            0.2820, -0.3897, -0.5524]]]))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "31d9592e-6fb5-4d71-aba7-59a7c6144927",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm_layer(inp, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "10743824-24bb-471d-951a-692fac6f3457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6ae80-d35c-49d3-bfcb-b70e86daa417",
   "metadata": {},
   "source": [
    "### LSTM #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "9dcd6d96-182d-47cd-a96f-7ed240f7afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = []\n",
    "        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "\n",
    "        for input_t in input.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "67744714-1661-48b9-a6ec-2acbbd5a1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "33962d60-c5c4-4f0a-a302-83b9130b82e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm1): LSTMCell(1, 51)\n",
       "  (lstm2): LSTMCell(51, 51)\n",
       "  (linear): Linear(in_features=51, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
