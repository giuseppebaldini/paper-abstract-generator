{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {},
   "source": [
    "# Conditional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31881b08-e995-4211-81f7-2c1f89835fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data = parse_file('data/anthology+abstracts.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ee3fa-f7a0-48fb-919b-a866b9bf053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bib_data.entries.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafa7ec-d2c0-42ad-9720-02b401c6ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(bib_data.entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568f11e-dcb1-4551-8a41-9bf8b654af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data.entries['lieberman-etal-1965-automatic'].fields['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a59e7e-50eb-45dd-8607-d219321259c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract)\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ad1b-0b2e-4210-9e99-94c6724d2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate stop words\n",
    "def tokenize_input(input):\n",
    "    # make everything lowercase\n",
    "    input = input.lower()\n",
    "\n",
    "    # use tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # filter out stopwords\n",
    "    final = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    \n",
    "    # end result in final\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cc7a9-6a06-4759-9314-d1a5dcd6b0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2016,2022):        \n",
    "        with open('data/datasets/abstracts_%s.txt' %year) as abstr:\n",
    "            lines = abstr.readlines()\n",
    "            processed = tokenize_input(lines[0])\n",
    "            \n",
    "            # create individual year files\n",
    "            y = open('data/datasets/%s.txt' %year, 'a')\n",
    "            y.write(processed)\n",
    "            \n",
    "            # create all years file\n",
    "            a = open('data/datasets/all.txt', 'a')\n",
    "            a.write(processed)\n",
    "            \n",
    "            y.close()\n",
    "            a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db46f9c-3081-4472-8cc9-cc62b1f81b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract + '\\n')\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d574e6c-5be4-4932-9578-0789473d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2016.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933158cf-9c36-40e3-b7c1-6ee45e32f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = [remove_stopwords(a) for a in abstracts]\n",
    "lowercase = [a.lower() for a in trimmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d10edbc-e5bf-45c4-afbf-493cbd1e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized = [tokenizer.tokenize(a) for a in lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660af61f-3939-4219-96e5-9d51bb5a6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokenized abstracts\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550c3d2a-f342-4a91-a916-94cac0fef847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'article',\n",
       " 'proposes',\n",
       " 'universal',\n",
       " 'dependency',\n",
       " 'annotation',\n",
       " 'scheme',\n",
       " 'mandarin',\n",
       " 'chinese',\n",
       " 'including',\n",
       " 'pos',\n",
       " 'tags',\n",
       " 'dependency',\n",
       " 'analysis',\n",
       " 'we',\n",
       " 'identify',\n",
       " 'cases',\n",
       " 'idiosyncrasy',\n",
       " 'mandarin',\n",
       " 'chinese',\n",
       " 'difficult',\n",
       " 'fit',\n",
       " 'current',\n",
       " 'schema',\n",
       " 'mainly',\n",
       " 'based',\n",
       " 'descriptions',\n",
       " 'indo',\n",
       " 'european',\n",
       " 'languages',\n",
       " 'we',\n",
       " 'discuss',\n",
       " 'differences',\n",
       " 'scheme',\n",
       " 'stanford',\n",
       " 'chinese',\n",
       " 'dependencies',\n",
       " 'chinese',\n",
       " 'dependency',\n",
       " 'treebank']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tokenized abstract\n",
    "tokenized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bf0748-9359-435f-93ea-8a366e643728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single word\n",
    "tokenized[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33379870-94d5-4d2e-a786-78040d51c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # could use itertools for improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d0da96-277b-4ae5-8dce-330251f14937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162958"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07f3b1-3d1d-4a18-98cf-45261a7b72d0",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba0dd7d-aaad-42b4-880b-f01c4dccbd78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newly'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = Dictionary(tokenized)\n",
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13614"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22a8a06-e8a2-4e66-8d5d-19ba5922eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim dict at 1000 tokens\n",
    "dct.filter_extremes(no_below=1, no_above=0.1, keep_n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9b1d0e-358c-4ac6-b688-e51101bc391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e43733-6f7e-41d6-a7e1-1c264532dc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'layers'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1000 unique tokens: ['0', '4', 'according', 'annotating', 'case']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(text) for text in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ff58d-7c9b-450a-bf83-518d70de82d3",
   "metadata": {},
   "source": [
    "### LDA (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9590b34-fe3b-45c5-925f-cc8bb31c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, num_topics=10, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d6120-5b44-45e0-ad8c-f3a77cbba6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac0bb7-53be-4860-bfaf-9856cc786cdd",
   "metadata": {},
   "source": [
    "### Doc2Vec (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c09238-591e-4bd0-9bca-02827842fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a207060-e36c-43e3-96b5-d23a75d8a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(documents, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c389e-0e7b-4075-a25b-35fd0c3ec7c3",
   "metadata": {},
   "source": [
    "### LSA (ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23f290-e1c1-4802-a2d2-78c99c312940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=10, decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320931a9-1e16-4890-8fbc-dcd1311646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da2234-e893-4f90-82e3-f45cae8734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topic(8, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba013f-0207-4346-a922-8f83271b4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86a9f8-69a5-4484-953b-a5374b71eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation = lsi.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f6a7c-9677-47e2-a782-2033157476f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.projection.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27085349-f8e1-412d-b6c1-d662b59af280",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12a05e-1a97-4ba1-a769-da71050edff8",
   "metadata": {},
   "source": [
    "## LSTM from scratch #1 (OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755975e-4bdf-4767-b0ab-f4b7b26e827c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cd53e27-9a22-4b32-9971-829f4a8006d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, words, dictionary, sequence_length=5): # TODO: incorporate dictionary\n",
    "        self.words = words[:2000]\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f6b2f-bb3f-453c-a457-4fdab09a129e",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14c26a8-9296-455d-ba81-3aeee89718a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset, lstm_size=256, emdedding_dim=256, num_layers=2, dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding_dim = emdedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.sequence_length = dataset.sequence_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, self.sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, self.sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1bb67-4d3b-4b7d-aa9d-4579ba6e9f56",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b66873a3-72f0-48c0-ba89-662bd4e9541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(dataset, model, batch_size=128, max_epochs=3):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 50 == 0:\n",
    "                print({ 'Epoch': epoch, 'Batch': batch, 'Loss': loss.item() })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09ed4a-bc3d-4a6a-8da9-046cd8fe6d38",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b85efe7-4860-4b4a-ad6e-69fcf567b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(dataset, model, text, next_words=100):\n",
    "    output = text.split(' ')\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in output[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        \n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        output.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65525b5-f993-400d-a16b-7dacd946a2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0, 'Batch': 0, 'Loss': 6.907998085021973}\n"
     ]
    }
   ],
   "source": [
    "text = 'in this paper we propose'\n",
    "\n",
    "dataset = Dataset(words, dct, sequence_length=len(text.split(' ')))\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f9e7e-d3b2-4b2d-bde2-0471036ab018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate(dataset, model, text=text, next_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9547f-259b-4e93-ab98-f2b56c9024aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index_to_word[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a7e92-dc29-4f8a-82c7-aa5038838508",
   "metadata": {},
   "source": [
    "## LSTM from scratch #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d607d-c1ae-42cc-a230-22d7553275d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # Number of samples per time step\n",
    "        self.batch_size = 1\n",
    "\n",
    "        # Dimension of weight vectors\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Dimension of embedded tensor\n",
    "        self.embedding_dim = 2\n",
    "\n",
    "        # Vocabulary size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Number of time steps\n",
    "        self.sequence_len = 1\n",
    "    \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_dim, padding_idx=0)\n",
    "    \n",
    "        # Initialize LSTM Cell\n",
    "        self.lstm_cell = nn.LSTMCell(self.embedding_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.tensor(x).to(device).long()\n",
    "\n",
    "        # batch_size x hidden_size\n",
    "        hidden_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cell_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        hidden_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "        cell_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "        # weights initialization\n",
    "        torch.nn.init.xavier_normal_(hidden_state)\n",
    "        torch.nn.init.xavier_normal_(cell_state)\n",
    "        torch.nn.init.xavier_normal_(hidden_state_2)\n",
    "        torch.nn.init.xavier_normal_(cell_state_2)\n",
    "\n",
    "        # From idx to embedding\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        # Prepare the shape for LSTMCell\n",
    "        out = out.view(self.sequence_len, x.size(0), -1)\n",
    "    \n",
    "        # Unfolding LSTM\n",
    "        # Last hidden_state will be used to feed the fully connected neural net\n",
    "        for i in range(self.sequence_len):\n",
    "            hidden_state, cell_state = self.lstm_cell_1(out[i], (hidden_state, cell_state))\n",
    "            hidden_state_2, cell_state_2 = self.lstm_cell_2(hidden_state, (hidden_state_2, cell_state_2))\n",
    "            \n",
    "        # Last hidden state is passed through a fully connected neural net\n",
    "        out = self.fully_connected(hidden_state_2)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2323509-77dc-4263-9023-3294a35cb114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def forward(self, x):\n",
    "\n",
    "#     # batch_size x hidden_size\n",
    "#     hidden_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     cell_state = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     hidden_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "#     cell_state_2 = torch.zeros(x.size(0), self.hidden_dim)\n",
    "\n",
    "#     # weights initialization\n",
    "#     torch.nn.init.xavier_normal_(hidden_state)\n",
    "#     torch.nn.init.xavier_normal_(cell_state)\n",
    "#     torch.nn.init.xavier_normal_(hidden_state_2)\n",
    "#     torch.nn.init.xavier_normal_(cell_state_2)\n",
    "\n",
    "#     # From idx to embedding\n",
    "#     out = self.embedding(x)\n",
    "\n",
    "#     # Prepare the shape for LSTMCell\n",
    "#     out = out.view(self.sequence_len, x.size(0), -1)\n",
    "    \n",
    "#     # Unfolding LSTM\n",
    "#     # Last hidden_state will be used to feed the fully connected neural net\n",
    "#     for i in range(self.sequence_len):\n",
    "#         hidden_state, cell_state = self.lstm_cell_1(out[i], (hidden_state, cell_state))\n",
    "#         hidden_state_2, cell_state_2 = self.lstm_cell_2(hidden_state, (hidden_state_2, cell_state_2))\n",
    "        \n",
    "#     # Last hidden state is passed through a fully connected neural net\n",
    "#     out = self.fully_connected(hidden_state_2)\n",
    "    \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2f682-f276-4cca-aa92-de763f48d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size=5, hidden_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c15cfb-f954-4c17-80a6-27157cb88faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cd38e-8adb-4877-bd0f-b9354dac20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa78d34-2235-40d6-b425-81b1da0616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(model.batch_size, model.sequence_len, model.input_size)\n",
    "hidden_state = torch.randn(n_layers, model.batch_size, model.hidden_dim)\n",
    "cell_state = torch.randn(n_layers, model.batch_size, model.hidden_dim)\n",
    "hidden = (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71767259-07dd-437f-b87f-c1369b12d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90aaa5b-bbf1-4404-aa06-c37b263b83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf3db8-b3d1-4460-8468-311257db0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd16d08-584a-496e-8c04-b2e1b120f44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe0c86-650f-45d8-a5c2-df6fc6fb9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim)\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 1\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6124d9a-b573-4479-bb23-06228faacd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9592e-6fb5-4d71-aba7-59a7c6144927",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm_layer(inp, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10743824-24bb-471d-951a-692fac6f3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6ae80-d35c-49d3-bfcb-b70e86daa417",
   "metadata": {},
   "source": [
    "### LSTM #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd6d96-182d-47cd-a96f-7ed240f7afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = nn.LSTMCell(51, 51)\n",
    "        self.linear = nn.Linear(51, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = []\n",
    "        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)\n",
    "\n",
    "        for input_t in input.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs += [output]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67744714-1661-48b9-a6ec-2acbbd5a1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33962d60-c5c4-4f0a-a302-83b9130b82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
