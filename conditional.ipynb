{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {},
   "source": [
    "# Conditional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441da77-9359-42e5-92c8-e31f0afba424",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parse bibtex files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31881b08-e995-4211-81f7-2c1f89835fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data = parse_file('data/anthology+abstracts.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ee3fa-f7a0-48fb-919b-a866b9bf053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bib_data.entries.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafa7ec-d2c0-42ad-9720-02b401c6ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(bib_data.entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568f11e-dcb1-4551-8a41-9bf8b654af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data.entries['lieberman-etal-1965-automatic'].fields['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a59e7e-50eb-45dd-8607-d219321259c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract)\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ad1b-0b2e-4210-9e99-94c6724d2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate stop words\n",
    "def tokenize_input(input):\n",
    "    # make everything lowercase\n",
    "    input = input.lower()\n",
    "\n",
    "    # use tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # filter out stopwords\n",
    "    final = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    \n",
    "    # end result in final\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cc7a9-6a06-4759-9314-d1a5dcd6b0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2016,2022):        \n",
    "        with open('data/datasets/abstracts_%s.txt' %year) as abstr:\n",
    "            lines = abstr.readlines()\n",
    "            processed = tokenize_input(lines[0])\n",
    "            \n",
    "            # create individual year files\n",
    "            y = open('data/datasets/%s.txt' %year, 'a')\n",
    "            y.write(processed)\n",
    "            \n",
    "            # create all years file\n",
    "            a = open('data/datasets/all.txt', 'a')\n",
    "            a.write(processed)\n",
    "            \n",
    "            y.close()\n",
    "            a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db46f9c-3081-4472-8cc9-cc62b1f81b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract + '\\n')\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "id": "5d574e6c-5be4-4932-9578-0789473d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2020.txt')\n",
    "text = f.read()\n",
    "abstracts_2020 = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "933158cf-9c36-40e3-b7c1-6ee45e32f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = [remove_stopwords(a) for a in abstracts_2020]\n",
    "lowercase = [a.lower() for a in trimmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "id": "4d10edbc-e5bf-45c4-afbf-493cbd1e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized = [tokenizer.tokenize(a) for a in lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "660af61f-3939-4219-96e5-9d51bb5a6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6499"
      ]
     },
     "execution_count": 1239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokenized abstracts\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "550c3d2a-f342-4a91-a916-94cac0fef847",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'relatedness',\n",
       "  'research',\n",
       "  'articles',\n",
       "  'patents',\n",
       "  'court',\n",
       "  'rulings',\n",
       "  'web',\n",
       "  'pages',\n",
       "  'document',\n",
       "  'types',\n",
       "  'calculated',\n",
       "  'citation',\n",
       "  'hyperlink',\n",
       "  'based',\n",
       "  'approaches',\n",
       "  'like',\n",
       "  'co',\n",
       "  'citation',\n",
       "  'proximity',\n",
       "  'analysis',\n",
       "  'the',\n",
       "  'main',\n",
       "  'limitation',\n",
       "  'citation',\n",
       "  'based',\n",
       "  'approaches',\n",
       "  'documents',\n",
       "  'receive',\n",
       "  'little',\n",
       "  'citations',\n",
       "  'we',\n",
       "  'propose',\n",
       "  'virtual',\n",
       "  'citation',\n",
       "  'proximity',\n",
       "  'vcp',\n",
       "  'siamese',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'architecture',\n",
       "  'combines',\n",
       "  'advantages',\n",
       "  'co',\n",
       "  'citation',\n",
       "  'proximity',\n",
       "  'analysis',\n",
       "  'diverse',\n",
       "  'notions',\n",
       "  'relatedness',\n",
       "  'high',\n",
       "  'recommendation',\n",
       "  'performance',\n",
       "  'advantage',\n",
       "  'content',\n",
       "  'based',\n",
       "  'filtering',\n",
       "  'high',\n",
       "  'coverage',\n",
       "  'vcp',\n",
       "  'trained',\n",
       "  'corpus',\n",
       "  'documents',\n",
       "  'textual',\n",
       "  'features',\n",
       "  'real',\n",
       "  'citation',\n",
       "  'proximity',\n",
       "  'ground',\n",
       "  'truth',\n",
       "  'vcp',\n",
       "  'predicts',\n",
       "  'documents',\n",
       "  'based',\n",
       "  'title',\n",
       "  'abstract',\n",
       "  'proximity',\n",
       "  'documents',\n",
       "  'co',\n",
       "  'cited',\n",
       "  'co',\n",
       "  'cited',\n",
       "  'the',\n",
       "  'prediction',\n",
       "  'way',\n",
       "  'real',\n",
       "  'citation',\n",
       "  'proximity',\n",
       "  'calculate',\n",
       "  'document',\n",
       "  'relatedness',\n",
       "  'uncited',\n",
       "  'documents',\n",
       "  'in',\n",
       "  'evaluation',\n",
       "  '2',\n",
       "  'million',\n",
       "  'co',\n",
       "  'citations',\n",
       "  'wikipedia',\n",
       "  'articles',\n",
       "  'vcp',\n",
       "  'achieves',\n",
       "  'mae',\n",
       "  '0',\n",
       "  '0055',\n",
       "  'i',\n",
       "  'e',\n",
       "  'improvement',\n",
       "  '20',\n",
       "  'baseline',\n",
       "  'learning',\n",
       "  'curve',\n",
       "  'suggests',\n",
       "  'work',\n",
       "  'needed'],\n",
       " ['the',\n",
       "  'question',\n",
       "  'utility',\n",
       "  'blind',\n",
       "  'peer',\n",
       "  'review',\n",
       "  'fundamental',\n",
       "  'scientific',\n",
       "  'research',\n",
       "  'some',\n",
       "  'studies',\n",
       "  'investigate',\n",
       "  'exactly',\n",
       "  'blind',\n",
       "  'papers',\n",
       "  'double',\n",
       "  'blind',\n",
       "  'review',\n",
       "  'manually',\n",
       "  'automatically',\n",
       "  'identifying',\n",
       "  'true',\n",
       "  'authors',\n",
       "  'mainly',\n",
       "  'suggesting',\n",
       "  'number',\n",
       "  'self',\n",
       "  'citations',\n",
       "  'submitted',\n",
       "  'manuscripts',\n",
       "  'primary',\n",
       "  'signal',\n",
       "  'identity',\n",
       "  'however',\n",
       "  'related',\n",
       "  'work',\n",
       "  'automated',\n",
       "  'approaches',\n",
       "  'limited',\n",
       "  'sizes',\n",
       "  'datasets',\n",
       "  'restricted',\n",
       "  'experimental',\n",
       "  'setup',\n",
       "  'lack',\n",
       "  'practical',\n",
       "  'insights',\n",
       "  'blind',\n",
       "  'review',\n",
       "  'process',\n",
       "  'in',\n",
       "  'work',\n",
       "  'train',\n",
       "  'models',\n",
       "  'identify',\n",
       "  'authors',\n",
       "  'affiliations',\n",
       "  'nationalities',\n",
       "  'real',\n",
       "  'world',\n",
       "  'large',\n",
       "  'scale',\n",
       "  'experiments',\n",
       "  'microsoft',\n",
       "  'academic',\n",
       "  'graph',\n",
       "  'including',\n",
       "  'cold',\n",
       "  'start',\n",
       "  'scenario',\n",
       "  'our',\n",
       "  'models',\n",
       "  'accurate',\n",
       "  'identify',\n",
       "  'authors',\n",
       "  'affiliations',\n",
       "  'nationalities',\n",
       "  'held',\n",
       "  'out',\n",
       "  'papers',\n",
       "  '40',\n",
       "  '3',\n",
       "  '47',\n",
       "  '9',\n",
       "  '86',\n",
       "  '0',\n",
       "  'accuracy',\n",
       "  'respectively',\n",
       "  'top',\n",
       "  '10',\n",
       "  'guesses',\n",
       "  'models',\n",
       "  'however',\n",
       "  'insights',\n",
       "  'model',\n",
       "  'demonstrate',\n",
       "  'entities',\n",
       "  'identifiable',\n",
       "  'small',\n",
       "  'number',\n",
       "  'guesses',\n",
       "  'primarily',\n",
       "  'combination',\n",
       "  'self',\n",
       "  'citations',\n",
       "  'social',\n",
       "  'common',\n",
       "  'citations',\n",
       "  'moreover',\n",
       "  'analysis',\n",
       "  'results',\n",
       "  'leads',\n",
       "  'interesting',\n",
       "  'findings',\n",
       "  'prominent',\n",
       "  'affiliations',\n",
       "  'easily',\n",
       "  'identifiable',\n",
       "  'e',\n",
       "  'g',\n",
       "  '93',\n",
       "  '8',\n",
       "  'test',\n",
       "  'papers',\n",
       "  'written',\n",
       "  'microsoft',\n",
       "  'identified',\n",
       "  'top',\n",
       "  '10',\n",
       "  'guesses',\n",
       "  'the',\n",
       "  'experimental',\n",
       "  'results',\n",
       "  'show',\n",
       "  'conventional',\n",
       "  'belief',\n",
       "  'self',\n",
       "  'citations',\n",
       "  'informative',\n",
       "  'looking',\n",
       "  'common',\n",
       "  'citations',\n",
       "  'suggesting',\n",
       "  'removing',\n",
       "  'self',\n",
       "  'citations',\n",
       "  'sufficient',\n",
       "  'authors',\n",
       "  'maintain',\n",
       "  'anonymity']]"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tokenized abstract\n",
    "tokenized[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "21bf0748-9359-435f-93ea-8a366e643728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patents'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single word\n",
    "tokenized[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "33379870-94d5-4d2e-a786-78040d51c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # could use itertools to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "98d0da96-277b-4ae5-8dce-330251f14937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606420"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12a05e-1a97-4ba1-a769-da71050edff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conditioned LSTM with Word2Vec embeddings #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755975e-4bdf-4767-b0ab-f4b7b26e827c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7cd53e27-9a22-4b32-9971-829f4a8006d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, words, sequence_length=5): # TODO: incorporate dictionary\n",
    "        self.words = words[:2000]\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3fdf5-7861-43b9-8b8d-e5336f6b6cc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "c7b86db1-c8d4-4a6e-9bd8-0f9baef54f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2020.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "93408750-4461-411d-8885-d1afb2f61d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "a6acc567-9917-47d5-8e92-4b10a33d9515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360959"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "22bd0254-1bcc-4c30-813d-9c197ea67072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(abstracts, min_count=1, vector_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "6e2d0549-4ff4-47ff-ac06-fd120ca00f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors = w2v_model.wv.vectors[:928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "6032eda5-ff4c-43aa-919b-d59e0d8cfcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 256)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "8f853203-9e07-4924-a3b8-93e41fb72811",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f6b2f-bb3f-453c-a457-4fdab09a129e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e14c26a8-9296-455d-ba81-3aeee89718a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset, lstm_size=256, emdedding_dim=256, num_layers=2, dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding_dim = emdedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.sequence_length = dataset.sequence_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, self.sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, self.sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1bb67-4d3b-4b7d-aa9d-4579ba6e9f56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "b66873a3-72f0-48c0-ba89-662bd4e9541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(dataset, model, batch_size=128, max_epochs=3):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 50 == 0:\n",
    "                print({ 'Epoch': epoch, 'Batch': batch, 'Loss': loss.item() })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09ed4a-bc3d-4a6a-8da9-046cd8fe6d38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "6b85efe7-4860-4b4a-ad6e-69fcf567b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "\n",
    "def generate(dataset, model, text, next_words=100):\n",
    "    output = text.split(' ')\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in output[i:]]])        \n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        output.append(dataset.index_to_word[word_index])\n",
    "\n",
    "        return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "b65525b5-f993-400d-a16b-7dacd946a2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0, 'Batch': 0, 'Loss': 6.8361334800720215}\n"
     ]
    }
   ],
   "source": [
    "input_text = 'in this paper we propose'\n",
    "\n",
    "dataset = Dataset(words, sequence_length=5)\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "803f9e7e-d3b2-4b2d-bde2-0471036ab018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate(dataset, model, text=text, next_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "70f9547f-259b-4e93-ab98-f2b56c9024aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'documents'"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index_to_word[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3f32fca4-cab4-43a0-954f-eeb910e744de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = words[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "26a4017b-3c09-474e-b0cf-73c085d5584f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evaluates'"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = len(dataset.uniq_words)\n",
    "dataset.uniq_words[810]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "5bef1399-056c-4654-9985-0fb25bb40317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.uniq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3636b8-4000-4cc8-b497-fe8f1b9fa4a4",
   "metadata": {},
   "source": [
    "## Conditioned LSTM with Word2Vec embeddings #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c4d09f-d9f1-4586-9c09-11abae885499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a5d4b5-00cd-415e-9159-0512ec2ad2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1735"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "f = open('data/datasets/abstracts_2021.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6baec2d-80f1-4297-998c-ebf35d1eb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [re.sub(\"[^a-z', ]\", \"\", a) for a in abstracts[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe343191-55af-48bb-b966-55ad552efcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task lthough the most common formulation of text ranking is search, instances of the task can also be found in many text processing applications his tutorial provides an overview of text ranking with neural network architectures known as transformers, of which  idirectional ncoder epresentations from ransformers is the bestknown example hese models produce high quality results across many domains, tasks, and settings his tutorial, which is based on the preprint of a forthcoming book to be published by organ and  laypool under the ynthesis ectures on uman anguage echnologies series, provides an overview of existing work as a single point of entry for practitioners who wish to deploy transformers for text ranking in realworld applications and researchers who wish to pursue work in this area e cover a wide range of techniques, grouped into two categories transformer models that perform reranking in multistage ranking architectures and learned dense representations that perform ranking directly',\n",
       " \"iamese eural etworks have been widely used to perform similarity classification in multiclass settings heir architecture can be used to group the clinical trials belonging to the same drugdevelopment pathway along the several clinical trial phases ere we present an approach for the unmet need of drugdevelopment pathway reconstruction, based on an nhanced hybrid iameseeep eural etwork nidet he proposed model demonstrates significant improvement above baselines in a shot evaluation setting and in a classical similarity setting nidet can be an essential tool in a semisupervised learning environment by selecting clinical trials highly likely to belong to the same drugdevelopment pathway it is possible to speed up the labelling process of human experts, allowing the check of a consistent volume of data, further used in the model's training dataset\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(abstracts, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac9ef4-d424-4830-a904-8ffcbae0c133",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce8d11f3-20fe-41d7-9a0c-53cb0d4bed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences of default length 5 tokens\n",
    "def create_seq(text, seq_len = 5):\n",
    "    \n",
    "    sequences = []\n",
    "\n",
    "    # if the number of tokens in 'text' is greater than 5\n",
    "    if len(text.split()) > seq_len:\n",
    "      for i in range(seq_len, len(text.split())):\n",
    "        # select sequence of tokens\n",
    "        seq = text.split()[i-seq_len:i+1]\n",
    "        # add to the list\n",
    "        sequences.append(\" \".join(seq))\n",
    "\n",
    "      return sequences\n",
    "\n",
    "    # if the number of tokens in 'text' is less than or equal to 5\n",
    "    else:\n",
    "      \n",
    "      return [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6908bb6-8f9a-4ca4-8e8a-49e6cbda4499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60851"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [create_seq(a) for a in abstracts]\n",
    "\n",
    "# merge list-of-lists into a single list\n",
    "seqs = sum(seqs, []) # could use itertools to improve performance\n",
    "\n",
    "# count of sequences\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29944832-1ae3-4c01-91df-b71c148a41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs and targets (x and y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for s in seqs:\n",
    "  x.append(\" \".join(s.split()[:-1]))\n",
    "  y.append(\" \".join(s.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ec94d17-2de0-4c9f-8538-520c44e00f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe2261ca-1b39-45cb-9c33-db5a846ecbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7081, 'stale')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create integer-to-token mapping\n",
    "int2token = {}\n",
    "counter = 0\n",
    "\n",
    "for w in set(\" \".join(abstracts).split()):\n",
    "  int2token[counter] = w\n",
    "  counter += 1\n",
    "\n",
    "# create token-to-integer mapping\n",
    "token2int = {t: a for a, t in int2token.items()}\n",
    "\n",
    "token2int[\"the\"], int2token[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3519a103-be94-4618-b692-fd37a944ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7775"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(int2token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cce3a579-a521-48a5-aba1-8b01e7e1f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "  return [token2int[w] for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x_int = [get_integer_seq(i) for i in x]\n",
    "y_int = [get_integer_seq(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b325c81-603e-4424-b0b3-4c571d2b2c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60851, 60851)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int),len(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2057e88f-3e11-4c92-a4a7-411ce3f85b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all sequences not == 5\n",
    "\n",
    "x_int = list(filter(lambda x: (len(x) == 5), x_int))\n",
    "y_int = list(filter(lambda y: (len(y) == 5), y_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73e76882-4f7a-4d84-a9de-9d10e83984e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60851, 60851)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int),len(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e948cd60-1d6e-41d3-9146-27c717950f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to numpy arrays\n",
    "x_int = np.array(x_int)\n",
    "y_int = np.array(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "129df162-b5dd-4fc5-9ffa-63b8765ec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "         \n",
    "    # iterate through the arrays\n",
    "    prv = 0\n",
    "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "      x = arr_x[prv:n]\n",
    "      y = arr_y[prv:n]\n",
    "      prv = n\n",
    "      yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5c04b-471d-4557-ba19-badf9bad12d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ebe8b95-b3a3-4bc8-aae9-d7e29781a512",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.2, lr=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, 256)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(256, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        \n",
    "        x = x.long()\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # if GPU is available\n",
    "        if (torch.cuda.is_available()):\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        # if GPU is not available\n",
    "        else:\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "318c4949-55c3-40d9-a382-9cc1ef9b9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (emb_layer): Embedding(7776, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=7776, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = Model()\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be4497a4-357f-47eb-9466-5e3001770e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=10, batch_size=32, lr=0.01, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(x_int, y_int, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cpu(), targets.cpu()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1).long())\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{} -\".format(e+1, epochs),\n",
    "                    \"Step: {} -\".format(counter),\n",
    "                    \"Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16d0cf0d-d128-4eb5-b5b9-8209f006a0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 - Step: 50 - Loss: 7.671520233154297\n",
      "Epoch: 1/5 - Step: 100 - Loss: 7.775917053222656\n",
      "Epoch: 1/5 - Step: 150 - Loss: 7.7291579246521\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c52dbb69c752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-398d1b497f7d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, batch_size, lr, clip, print_every)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# update weigths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mparam_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mtotal_norm\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"nuc\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fro\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, batch_size=32, epochs=5, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "id": "1542bc82-cb1a-4ddc-af39-be52eb00bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next token\n",
    "def predict(model, tkn, h=None):\n",
    "         \n",
    "  # tensor inputs\n",
    "  x = np.array([[token2int[tkn]]])\n",
    "  inputs = torch.from_numpy(x)\n",
    "  \n",
    "  # push to CPU\n",
    "  inputs = inputs.cpu()\n",
    "\n",
    "  # detach hidden state from history\n",
    "  h = tuple([each.data for each in h])\n",
    "\n",
    "  # get the output of the model\n",
    "  out, h = model(inputs, h)\n",
    "\n",
    "  # get the token probabilities\n",
    "  p = F.softmax(out, dim=1).data\n",
    "\n",
    "  p = p.cpu()\n",
    "\n",
    "  p = p.numpy()\n",
    "  p = p.reshape(p.shape[1],)\n",
    "\n",
    "  # get indices of top 3 values\n",
    "  top_n_idx = p.argsort()[-3:][::-1]\n",
    "\n",
    "  # randomly select one of the three indices\n",
    "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "\n",
    "  # return the encoded value of the predicted char and the hidden state\n",
    "  return int2token[sampled_token_index], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "913b9806-ea23-469f-89a6-0d7ff46a33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate text\n",
    "def generate(model, size, prompt='in this paper'):\n",
    "        \n",
    "    # push to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # batch size is 1\n",
    "    h = model.init_hidden(1)\n",
    "\n",
    "    toks = prompt.split()\n",
    "\n",
    "    # predict next token\n",
    "    for t in prompt.split():\n",
    "      token, h = predict(model, t, h)\n",
    "    \n",
    "    toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(size-1):\n",
    "        token, h = predict(model, toks[-1], h)\n",
    "        toks.append(token)\n",
    "\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "645a8dd9-4a9c-4059-8c23-28e753ca0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temporal word embeddings and the corresponding and a new training and the language understanding and a new training models and the corresponding the best neural network on three the same datasets to the model to a novel model can effectively a new training models to a novel reasoning the model can achieve the'"
      ]
     },
     "execution_count": 1233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model, 50, prompt='temporal word embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b41c59-892c-4d69-a19c-99e67d639e94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f11b1b-56b9-4ca6-82a2-272235fbab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3b616a-5ad3-4ca8-8e68-04c52b338c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "words_abstracts = [a.split(' ') for a in abstracts] # could use itertools to improve performance\n",
    "words = list(itertools.chain(*words_abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131611a3-9a5e-4213-bd77-a022dd13ec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 65068)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_abstracts), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "id": "8b6c116d-cc19-4fcc-b4f4-a51e43814210",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['espite',\n",
       "  'the',\n",
       "  'recent',\n",
       "  'successes',\n",
       "  'of',\n",
       "  'transformerbased',\n",
       "  'models',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'effectiveness',\n",
       "  'on',\n",
       "  'a',\n",
       "  'variety',\n",
       "  'of',\n",
       "  'tasks,',\n",
       "  'their',\n",
       "  'decisions',\n",
       "  'often',\n",
       "  'remain',\n",
       "  'opaque',\n",
       "  'to',\n",
       "  'humans',\n",
       "  'xplanations',\n",
       "  'are',\n",
       "  'particularly',\n",
       "  'important',\n",
       "  'for',\n",
       "  'tasks',\n",
       "  'like',\n",
       "  'offensive',\n",
       "  'language',\n",
       "  'or',\n",
       "  'toxicity',\n",
       "  'detection',\n",
       "  'on',\n",
       "  'social',\n",
       "  'media',\n",
       "  'because',\n",
       "  'a',\n",
       "  'manual',\n",
       "  'appeal',\n",
       "  'process',\n",
       "  'is',\n",
       "  'often',\n",
       "  'in',\n",
       "  'place',\n",
       "  'to',\n",
       "  'dispute',\n",
       "  'automatically',\n",
       "  'flagged',\n",
       "  'content',\n",
       "  'n',\n",
       "  'this',\n",
       "  'work,',\n",
       "  'we',\n",
       "  'propose',\n",
       "  'a',\n",
       "  'technique',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'the',\n",
       "  'interpretability',\n",
       "  'of',\n",
       "  'these',\n",
       "  'models,',\n",
       "  'based',\n",
       "  'on',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'and',\n",
       "  'powerful',\n",
       "  'assumption',\n",
       "  'a',\n",
       "  'post',\n",
       "  'is',\n",
       "  'at',\n",
       "  'least',\n",
       "  'as',\n",
       "  'toxic',\n",
       "  'as',\n",
       "  'its',\n",
       "  'most',\n",
       "  'toxic',\n",
       "  'span',\n",
       "  'e',\n",
       "  'incorporate',\n",
       "  'this',\n",
       "  'assumption',\n",
       "  'into',\n",
       "  'transformer',\n",
       "  'models',\n",
       "  'by',\n",
       "  'scoring',\n",
       "  'a',\n",
       "  'post',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'maximum',\n",
       "  'toxicity',\n",
       "  'of',\n",
       "  'its',\n",
       "  'spans',\n",
       "  'and',\n",
       "  'augmenting',\n",
       "  'the',\n",
       "  'training',\n",
       "  'process',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'correct',\n",
       "  'spans',\n",
       "  'e',\n",
       "  'find',\n",
       "  'this',\n",
       "  'approach',\n",
       "  'effective',\n",
       "  'and',\n",
       "  'can',\n",
       "  'produce',\n",
       "  'explanations',\n",
       "  'that',\n",
       "  'exceed',\n",
       "  'the',\n",
       "  'quality',\n",
       "  'of',\n",
       "  'those',\n",
       "  'provided',\n",
       "  'by',\n",
       "  'ogistic',\n",
       "  'egression',\n",
       "  'analysis',\n",
       "  'often',\n",
       "  'regarded',\n",
       "  'as',\n",
       "  'a',\n",
       "  'highlyinterpretable',\n",
       "  'model,',\n",
       "  'according',\n",
       "  'to',\n",
       "  'a',\n",
       "  'human',\n",
       "  'study'],\n",
       " ['he',\n",
       "  'aim',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paper',\n",
       "  'is',\n",
       "  'twofold',\n",
       "  '',\n",
       "  'to',\n",
       "  'automatically',\n",
       "  'predict',\n",
       "  'the',\n",
       "  'ratings',\n",
       "  'assigned',\n",
       "  'by',\n",
       "  'viewers',\n",
       "  'to',\n",
       "  '',\n",
       "  'categories',\n",
       "  'available',\n",
       "  'for',\n",
       "  '',\n",
       "  'talks',\n",
       "  'in',\n",
       "  'a',\n",
       "  'multilabel',\n",
       "  'classification',\n",
       "  'task',\n",
       "  'and',\n",
       "  '',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'what',\n",
       "  'types',\n",
       "  'of',\n",
       "  'features',\n",
       "  'drive',\n",
       "  'classification',\n",
       "  'accuracy',\n",
       "  'for',\n",
       "  'each',\n",
       "  'of',\n",
       "  'the',\n",
       "  'categories',\n",
       "  'he',\n",
       "  'focus',\n",
       "  'is',\n",
       "  'on',\n",
       "  'features',\n",
       "  'of',\n",
       "  'language',\n",
       "  'usage',\n",
       "  'from',\n",
       "  'five',\n",
       "  'groups',\n",
       "  'pertaining',\n",
       "  'to',\n",
       "  'syntactic',\n",
       "  'complexity,',\n",
       "  'lexical',\n",
       "  'richness,',\n",
       "  'registerbased',\n",
       "  'ngram',\n",
       "  'measures,',\n",
       "  'informationtheoretic',\n",
       "  'measures',\n",
       "  'and',\n",
       "  'style',\n",
       "  'measures',\n",
       "  'e',\n",
       "  'show',\n",
       "  'that',\n",
       "  'a',\n",
       "  'ecurrent',\n",
       "  'eural',\n",
       "  'etwork',\n",
       "  'classifier',\n",
       "  'trained',\n",
       "  'exclusively',\n",
       "  'on',\n",
       "  'withintext',\n",
       "  'distributions',\n",
       "  'of',\n",
       "  'such',\n",
       "  'features',\n",
       "  'can',\n",
       "  'reach',\n",
       "  'relatively',\n",
       "  'high',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'overall',\n",
       "  'accuracy',\n",
       "  '',\n",
       "  'across',\n",
       "  'the',\n",
       "  '',\n",
       "  'categories',\n",
       "  'e',\n",
       "  'find',\n",
       "  'that',\n",
       "  'features',\n",
       "  'from',\n",
       "  'two',\n",
       "  'groups',\n",
       "  'are',\n",
       "  'strong',\n",
       "  'predictors',\n",
       "  'of',\n",
       "  'the',\n",
       "  'affective',\n",
       "  'ratings',\n",
       "  'across',\n",
       "  'all',\n",
       "  'categories',\n",
       "  'and',\n",
       "  'that',\n",
       "  'there',\n",
       "  'are',\n",
       "  'distinct',\n",
       "  'patterns',\n",
       "  'of',\n",
       "  'language',\n",
       "  'usage',\n",
       "  'for',\n",
       "  'each',\n",
       "  'rating',\n",
       "  'category']]"
      ]
     },
     "execution_count": 1330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_abstracts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb11fd5-6469-4edd-ab5a-4a15df763171",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(words_abstracts, min_count=1, vector_size=256, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c85555-9373-4f7e-bcd7-2a656f3a6012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb_vectors = w2v_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8877d36c-3f6b-407b-8d58-cce35e907568",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-73c20a5dcb30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memb_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vectors.kv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "emb_vectors.save('vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9274ce-6a3d-4f13-ada4-3b550b91f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7776, 256)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92882081-da42-4adc-8c5a-9c2e0d4413be",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_tensors = torch.FloatTensor(emb_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387df42a-1710-4b02-8040-fb6c52d24444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f29d96ad-cd40-425f-8d62-d05226d2740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fct(text):  # create a tokenizer function\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aed8653a-518d-49d5-a75c-e58cb8ee8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(sequential=True, use_vocab=True,\n",
    "                        lower=True, tokenize=tokenize_fct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "id": "83a96731-20f2-4dc6-9ec0-af832e5b30f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/26056 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Vector for token b'\\x80\\x04\\x95\\x05\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x1agensim.models.keyedvectors\\x94\\x8c\\x0cKeyedVectors\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0bvector_size\\x94M\\x00\\x01\\x8c\\x0cindex_to_key\\x94]\\x94(\\x8c\\x03the\\x94\\x8c\\x02of\\x94\\x8c\\x03and\\x94\\x8c\\x00\\x94\\x8c\\x02to\\x94\\x8c\\x01a\\x94\\x8c\\x02in\\x94\\x8c\\x03for\\x94\\x8c\\x02on\\x94\\x8c\\x04that\\x94\\x8c\\x02we\\x94\\x8c\\x02is\\x94\\x8c\\x01e\\x94\\x8c\\x04with\\x94\\x8c\\x04this\\x94\\x8c\\x06models\\x94\\x8c\\x05model\\x94\\x8c\\x02as\\x94\\x8c\\x04from\\x94\\x8c\\x02by\\x94\\x8c\\x08language\\x94\\x8c\\x03are\\x94\\x8c\\x02an\\x94\\x8c\\x01n\\x94\\x8c\\x02he\\x94\\x8c\\x03our\\x94\\x8c\\x04data\\x94\\x8c\\x04task\\x94\\x8c\\x05which\\x94\\x8c\\x02be\\x94\\x8c\\x03can\\x94\\x8c\\x05tasks\\x94\\x8c\\x0bperformance\\x94\\x8c\\x01,\\x94\\x8c\\x02or\\x94\\x8c\\x07results\\x94\\x8c\\x02ur\\x94\\x8c\\x05using\\x94\\x8c\\x03his\\x94\\x8c\\x04show\\x94\\x8c\\x04have\\x94\\x8c\\x08learning\\x94\\x8c\\x08training\\x94\\x8c\\x03has\\x94\\x8c\\x03two\\x94\\x8c\\x05based\\x94\\x8c\\x04text\\x94\\x8c\\x04such\\x94\\x8c\\x02it\\x94\\x8c\\x07propose\\x94\\x8c\\tlanguages\\x94\\x8c\\x08approach\\x94\\x8c\\x07dataset\\x94\\x8c\\tdifferent\\x94\\x8c\\x03new\\x94\\x8c\\x0binformation\\x94\\x8c\\x05their\\x94\\x8c\\x07present\\x94\\x8c\\x02at\\x94\\x8c\\x04more\\x94\\x8c\\x03not\\x94\\x8c\\x05rabic\\x94\\x8c\\x06method\\x94\\x8c\\x05these\\x94\\x8c\\x04both\\x94\\x8c\\x06neural\\x94\\x8c\\x06paper,\\x94\\x8c\\x03use\\x94\\x8c\\x07methods\\x94\\x8c\\x04work\\x94\\x8c\\x04been\\x94\\x8c\\x07between\\x94\\x8c\\x04also\\x94\\x8c\\rstateoftheart\\x94\\x8c\\x05paper\\x94\\x8c\\x01o\\x94\\x8c\\x04over\\x94\\x8c\\x06shared\\x94\\x8c' has 0 dimensions, but previously read vectors have None dimensions. All vectors must have the same number of dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1350-db5a0ee7a6ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_embs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vectors.kv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torchtext\\vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torchtext\\vocab.py\u001b[0m in \u001b[0;36mcache\u001b[1;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[0;32m    404\u001b[0m                             \u001b[1;34m\"read vectors have {} dimensions. All vectors must have \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                             \"the same number of dimensions.\".format(word, len(entries),\n\u001b[1;32m--> 406\u001b[1;33m                                                                     dim))\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Vector for token b'\\x80\\x04\\x95\\x05\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x1agensim.models.keyedvectors\\x94\\x8c\\x0cKeyedVectors\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0bvector_size\\x94M\\x00\\x01\\x8c\\x0cindex_to_key\\x94]\\x94(\\x8c\\x03the\\x94\\x8c\\x02of\\x94\\x8c\\x03and\\x94\\x8c\\x00\\x94\\x8c\\x02to\\x94\\x8c\\x01a\\x94\\x8c\\x02in\\x94\\x8c\\x03for\\x94\\x8c\\x02on\\x94\\x8c\\x04that\\x94\\x8c\\x02we\\x94\\x8c\\x02is\\x94\\x8c\\x01e\\x94\\x8c\\x04with\\x94\\x8c\\x04this\\x94\\x8c\\x06models\\x94\\x8c\\x05model\\x94\\x8c\\x02as\\x94\\x8c\\x04from\\x94\\x8c\\x02by\\x94\\x8c\\x08language\\x94\\x8c\\x03are\\x94\\x8c\\x02an\\x94\\x8c\\x01n\\x94\\x8c\\x02he\\x94\\x8c\\x03our\\x94\\x8c\\x04data\\x94\\x8c\\x04task\\x94\\x8c\\x05which\\x94\\x8c\\x02be\\x94\\x8c\\x03can\\x94\\x8c\\x05tasks\\x94\\x8c\\x0bperformance\\x94\\x8c\\x01,\\x94\\x8c\\x02or\\x94\\x8c\\x07results\\x94\\x8c\\x02ur\\x94\\x8c\\x05using\\x94\\x8c\\x03his\\x94\\x8c\\x04show\\x94\\x8c\\x04have\\x94\\x8c\\x08learning\\x94\\x8c\\x08training\\x94\\x8c\\x03has\\x94\\x8c\\x03two\\x94\\x8c\\x05based\\x94\\x8c\\x04text\\x94\\x8c\\x04such\\x94\\x8c\\x02it\\x94\\x8c\\x07propose\\x94\\x8c\\tlanguages\\x94\\x8c\\x08approach\\x94\\x8c\\x07dataset\\x94\\x8c\\tdifferent\\x94\\x8c\\x03new\\x94\\x8c\\x0binformation\\x94\\x8c\\x05their\\x94\\x8c\\x07present\\x94\\x8c\\x02at\\x94\\x8c\\x04more\\x94\\x8c\\x03not\\x94\\x8c\\x05rabic\\x94\\x8c\\x06method\\x94\\x8c\\x05these\\x94\\x8c\\x04both\\x94\\x8c\\x06neural\\x94\\x8c\\x06paper,\\x94\\x8c\\x03use\\x94\\x8c\\x07methods\\x94\\x8c\\x04work\\x94\\x8c\\x04been\\x94\\x8c\\x07between\\x94\\x8c\\x04also\\x94\\x8c\\rstateoftheart\\x94\\x8c\\x05paper\\x94\\x8c\\x01o\\x94\\x8c\\x04over\\x94\\x8c\\x06shared\\x94\\x8c' has 0 dimensions, but previously read vectors have None dimensions. All vectors must have the same number of dimensions."
     ]
    }
   ],
   "source": [
    "test_embs = Vectors(name='vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "id": "59409c2a-df4f-4a1c-8506-f5f89dbb53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(words, vectors=test_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "id": "63ee2f0a-ff60-4a4e-ab8d-bb49063eecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text vocab size 30\n"
     ]
    }
   ],
   "source": [
    "print(f'text vocab size {len(text_field.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33906745-7907-4aea-b48f-df2bf669b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801312e8-aed1-41a9-85cb-9b220b850255",
   "metadata": {},
   "source": [
    "#### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "5ba0dd7d-aaad-42b4-880b-f01c4dccbd78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'its'"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = Dictionary(words_abstracts)\n",
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7776"
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7776 unique tokens: ['a', 'according', 'analysis', 'and', 'appeal']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(text) for text in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ff58d-7c9b-450a-bf83-518d70de82d3",
   "metadata": {},
   "source": [
    "### LDA (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9590b34-fe3b-45c5-925f-cc8bb31c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, num_topics=10, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d6120-5b44-45e0-ad8c-f3a77cbba6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac0bb7-53be-4860-bfaf-9856cc786cdd",
   "metadata": {},
   "source": [
    "### Doc2Vec (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c09238-591e-4bd0-9bca-02827842fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a207060-e36c-43e3-96b5-d23a75d8a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(documents, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c389e-0e7b-4075-a25b-35fd0c3ec7c3",
   "metadata": {},
   "source": [
    "### LSA (ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23f290-e1c1-4802-a2d2-78c99c312940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=10, decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320931a9-1e16-4890-8fbc-dcd1311646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da2234-e893-4f90-82e3-f45cae8734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topic(8, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba013f-0207-4346-a922-8f83271b4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86a9f8-69a5-4484-953b-a5374b71eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation = lsi.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f6a7c-9677-47e2-a782-2033157476f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.projection.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "27085349-f8e1-412d-b6c1-d662b59af280",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_representation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1251-f620bb3d6011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtopic_representation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_representation' is not defined"
     ]
    }
   ],
   "source": [
    "topic_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82a6de5d-722f-447c-be5e-3c1b4f8b9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.2, lr=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        vocab_size = emb_vectors.shape[0]\n",
    "        \n",
    "        self.emb_layer = nn.Embedding.from_pretrained(emb_tensors)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(256, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        \n",
    "        x = x.long()\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # if GPU is available\n",
    "        if (torch.cuda.is_available()):\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        # if GPU is not available\n",
    "        else:\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c937378-041e-497b-9a78-218e2d5de95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
