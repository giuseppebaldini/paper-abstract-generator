{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {},
   "source": [
    "# Conditional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31881b08-e995-4211-81f7-2c1f89835fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data = parse_file('data/anthology+abstracts.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ee3fa-f7a0-48fb-919b-a866b9bf053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bib_data.entries.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafa7ec-d2c0-42ad-9720-02b401c6ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(bib_data.entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568f11e-dcb1-4551-8a41-9bf8b654af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data.entries['lieberman-etal-1965-automatic'].fields['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a59e7e-50eb-45dd-8607-d219321259c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract)\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ad1b-0b2e-4210-9e99-94c6724d2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate stop words\n",
    "def tokenize_input(input):\n",
    "    # make everything lowercase\n",
    "    input = input.lower()\n",
    "\n",
    "    # use tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "\n",
    "    # filter out stopwords\n",
    "    final = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    \n",
    "    # end result in final\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9cc7a9-6a06-4759-9314-d1a5dcd6b0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(2016,2022):        \n",
    "        with open('data/datasets/abstracts_%s.txt' %year) as abstr:\n",
    "            lines = abstr.readlines()\n",
    "            processed = tokenize_input(lines[0])\n",
    "            \n",
    "            # create individual year files\n",
    "            y = open('data/datasets/%s.txt' %year, 'a')\n",
    "            y.write(processed)\n",
    "            \n",
    "            # create all years file\n",
    "            a = open('data/datasets/all.txt', 'a')\n",
    "            a.write(processed)\n",
    "            \n",
    "            y.close()\n",
    "            a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db46f9c-3081-4472-8cc9-cc62b1f81b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            f = open('data/datasets/abstracts_%s.txt' %year, 'a')\n",
    "            f.write(abstract + '\\n')\n",
    "            f.close()\n",
    "            \n",
    "    except (KeyError, UnicodeEncodeError): # entries without abstracts are excluded\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5d574e6c-5be4-4932-9578-0789473d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2020.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "933158cf-9c36-40e3-b7c1-6ee45e32f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = [remove_stopwords(a) for a in abstracts]\n",
    "lowercase = [a.lower() for a in trimmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "4d10edbc-e5bf-45c4-afbf-493cbd1e2e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized = [tokenizer.tokenize(a) for a in lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "660af61f-3939-4219-96e5-9d51bb5a6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6499"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokenized abstracts\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "550c3d2a-f342-4a91-a916-94cac0fef847",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " 'introduce',\n",
       " 'smartcitecon',\n",
       " 'scc',\n",
       " 'java',\n",
       " 'api',\n",
       " 'extracting',\n",
       " 'explicit',\n",
       " 'implicit',\n",
       " 'citation',\n",
       " 'context',\n",
       " 'academic',\n",
       " 'literature',\n",
       " 'english',\n",
       " 'the',\n",
       " 'tool',\n",
       " 'built',\n",
       " 'support',\n",
       " 'vector',\n",
       " 'machine',\n",
       " 'svm',\n",
       " 'model',\n",
       " 'trained',\n",
       " 'set',\n",
       " '7',\n",
       " '058',\n",
       " 'manually',\n",
       " 'annotated',\n",
       " 'citation',\n",
       " 'context',\n",
       " 'sentences',\n",
       " 'curated',\n",
       " '34',\n",
       " '000',\n",
       " 'papers',\n",
       " 'acl',\n",
       " 'anthology',\n",
       " 'the',\n",
       " 'model',\n",
       " '19',\n",
       " 'features',\n",
       " 'achieves',\n",
       " 'f1',\n",
       " '85',\n",
       " '6',\n",
       " 'scc',\n",
       " 'supports',\n",
       " 'pdf',\n",
       " 'xml',\n",
       " 'json',\n",
       " 'files',\n",
       " 'out',\n",
       " 'of',\n",
       " 'box',\n",
       " 'provided',\n",
       " 'conformed',\n",
       " 'certain',\n",
       " 'schemas',\n",
       " 'the',\n",
       " 'api',\n",
       " 'supports',\n",
       " 'single',\n",
       " 'document',\n",
       " 'processing',\n",
       " 'batch',\n",
       " 'processing',\n",
       " 'parallel',\n",
       " 'it',\n",
       " 'takes',\n",
       " '12',\n",
       " '45',\n",
       " 'seconds',\n",
       " 'average',\n",
       " 'depending',\n",
       " 'format',\n",
       " 'process',\n",
       " 'document',\n",
       " 'dedicated',\n",
       " 'server',\n",
       " '6',\n",
       " 'multithreaded',\n",
       " 'cores',\n",
       " 'using',\n",
       " 'scc',\n",
       " 'extracted',\n",
       " '11',\n",
       " '8',\n",
       " 'million',\n",
       " 'citation',\n",
       " 'context',\n",
       " 'sentences',\n",
       " 'textasciitilde',\n",
       " '33',\n",
       " '3k',\n",
       " 'pmc',\n",
       " 'papers',\n",
       " 'cord',\n",
       " '19',\n",
       " 'dataset',\n",
       " 'released',\n",
       " 'june',\n",
       " '13',\n",
       " '2020',\n",
       " 'we',\n",
       " 'provide',\n",
       " 'continuous',\n",
       " 'supplementary',\n",
       " 'data',\n",
       " 'contribution',\n",
       " 'cord',\n",
       " '19',\n",
       " 'datasets',\n",
       " 'the',\n",
       " 'source',\n",
       " 'code',\n",
       " 'released',\n",
       " 'https',\n",
       " 'gitee',\n",
       " 'com',\n",
       " 'irlab',\n",
       " 'smartcitecon']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tokenized abstract\n",
    "tokenized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "21bf0748-9359-435f-93ea-8a366e643728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patents'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single word\n",
    "tokenized[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "33379870-94d5-4d2e-a786-78040d51c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # could use itertools to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "98d0da96-277b-4ae5-8dce-330251f14937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606420"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07f3b1-3d1d-4a18-98cf-45261a7b72d0",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "5ba0dd7d-aaad-42b4-880b-f01c4dccbd78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'little'"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = Dictionary(tokenized)\n",
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24741"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "f22a8a06-e8a2-4e66-8d5d-19ba5922eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim dict at 1000 tokens\n",
    "dct.filter_extremes(no_below=1, no_above=0.1, keep_n=928)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "4f9b1d0e-358c-4ac6-b688-e51101bc391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "e9e43733-6f7e-41d6-a7e1-1c264532dc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entities'"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(811 unique tokens: ['0', '20', 'achieves', 'advantage', 'architecture']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(text) for text in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ff58d-7c9b-450a-bf83-518d70de82d3",
   "metadata": {},
   "source": [
    "### LDA (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9590b34-fe3b-45c5-925f-cc8bb31c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus, num_topics=10, id2word=dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d6120-5b44-45e0-ad8c-f3a77cbba6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac0bb7-53be-4860-bfaf-9856cc786cdd",
   "metadata": {},
   "source": [
    "### Doc2Vec (unordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c09238-591e-4bd0-9bca-02827842fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenized)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a207060-e36c-43e3-96b5-d23a75d8a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(documents, vector_size=10, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c389e-0e7b-4075-a25b-35fd0c3ec7c3",
   "metadata": {},
   "source": [
    "### LSA (ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23f290-e1c1-4802-a2d2-78c99c312940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=10, decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320931a9-1e16-4890-8fbc-dcd1311646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da2234-e893-4f90-82e3-f45cae8734df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.show_topic(8, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba013f-0207-4346-a922-8f83271b4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86a9f8-69a5-4484-953b-a5374b71eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation = lsi.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f6a7c-9677-47e2-a782-2033157476f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.projection.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27085349-f8e1-412d-b6c1-d662b59af280",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12a05e-1a97-4ba1-a769-da71050edff8",
   "metadata": {},
   "source": [
    "## Conditioned LSTM with Word2Vec embeddings #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755975e-4bdf-4767-b0ab-f4b7b26e827c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "7cd53e27-9a22-4b32-9971-829f4a8006d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, words, sequence_length=5): # TODO: incorporate dictionary\n",
    "        self.words = words[:2000]\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3fdf5-7861-43b9-8b8d-e5336f6b6cc5",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "c7b86db1-c8d4-4a6e-9bd8-0f9baef54f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/datasets/abstracts_2020.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "93408750-4461-411d-8885-d1afb2f61d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for abstract in tokenized for word in abstract] # could use itertools to improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "a6acc567-9917-47d5-8e92-4b10a33d9515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606420"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "22bd0254-1bcc-4c30-813d-9c197ea67072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec(abstracts, min_count=1, vector_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "6e2d0549-4ff4-47ff-ac06-fd120ca00f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors = w2v_model.wv.vectors[:928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "6032eda5-ff4c-43aa-919b-d59e0d8cfcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 256)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "8f853203-9e07-4924-a3b8-93e41fb72811",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f6b2f-bb3f-453c-a457-4fdab09a129e",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e14c26a8-9296-455d-ba81-3aeee89718a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset, lstm_size=256, emdedding_dim=256, num_layers=2, dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding_dim = emdedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.sequence_length = dataset.sequence_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, self.sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, self.sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1bb67-4d3b-4b7d-aa9d-4579ba6e9f56",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "b66873a3-72f0-48c0-ba89-662bd4e9541c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(dataset, model, batch_size=128, max_epochs=3):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 50 == 0:\n",
    "                print({ 'Epoch': epoch, 'Batch': batch, 'Loss': loss.item() })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09ed4a-bc3d-4a6a-8da9-046cd8fe6d38",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "6b85efe7-4860-4b4a-ad6e-69fcf567b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "\n",
    "def generate(dataset, model, text, next_words=100):\n",
    "    output = text.split(' ')\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.init_state(model.sequence_length)\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in output[i:]]])        \n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        output.append(dataset.index_to_word[word_index])\n",
    "\n",
    "        return ' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "b65525b5-f993-400d-a16b-7dacd946a2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0, 'Batch': 0, 'Loss': 6.8361334800720215}\n"
     ]
    }
   ],
   "source": [
    "input_text = 'in this paper we propose'\n",
    "\n",
    "dataset = Dataset(words, sequence_length=5)\n",
    "model = Model(dataset)\n",
    "\n",
    "train(dataset, model, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "803f9e7e-d3b2-4b2d-bde2-0471036ab018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate(dataset, model, text=text, next_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "70f9547f-259b-4e93-ab98-f2b56c9024aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'documents'"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.index_to_word[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3f32fca4-cab4-43a0-954f-eeb910e744de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = words[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "26a4017b-3c09-474e-b0cf-73c085d5584f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evaluates'"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab = len(dataset.uniq_words)\n",
    "dataset.uniq_words[810]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "5bef1399-056c-4654-9985-0fb25bb40317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.uniq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3636b8-4000-4cc8-b497-fe8f1b9fa4a4",
   "metadata": {},
   "source": [
    "## Conditioned LSTM with Word2Vec embeddings #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "e3c4d09f-d9f1-4586-9c09-11abae885499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "a1a5d4b5-00cd-415e-9159-0512ec2ad2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1735"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "f = open('data/datasets/abstracts_2021.txt')\n",
    "text = f.read()\n",
    "abstracts = text.split('\\n')\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "555a841d-b255-4fd2-9b60-b9766a6740af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read pickle file\n",
    "pickle_in = open(\"plots_text.pickle\",\"rb\")\n",
    "abstracts = pickle.load(pickle_in)\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "f6baec2d-80f1-4297-998c-ebf35d1eb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = [re.sub(\"[^a-z', ]\", \"\", a) for a in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "fe343191-55af-48bb-b966-55ad552efcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he aim of the paper is twofold  to automatically predict the ratings assigned by viewers to  categories available for  talks in a multilabel classification task and  to determine what types of features drive classification accuracy for each of the categories he focus is on features of language usage from five groups pertaining to syntactic complexity, lexical richness, registerbased ngram measures, informationtheoretic measures and style measures e show that a ecurrent eural etwork classifier trained exclusively on withintext distributions of such features can reach relatively high levels of overall accuracy  across the  categories e find that features from two groups are strong predictors of the affective ratings across all categories and that there are distinct patterns of language usage for each rating category',\n",
       " 'his paper addresses the problem of sentiment analysis for opara, a codeswitching language between uarani and panish e first collect a corpus of uaranidominant tweets and discuss on the difficulties of finding quality data for even relatively easytoannotate tasks, such as sentiment analysis hen, we train a set of neural models, including pretrained language models, and explore whether they perform better than traditional machine learning ones in this lowresource setup ransformer architectures obtain the best results, despite not considering uarani during pretraining, but traditional machine learning models perform close due to the lowresource nature of the problem']"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(abstracts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "ce8d11f3-20fe-41d7-9a0c-53cb0d4bed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences of default length 5 tokens\n",
    "def create_seq(text, seq_len = 5):\n",
    "    \n",
    "    sequences = []\n",
    "\n",
    "    # if the number of tokens in 'text' is greater than 5\n",
    "    if len(text.split()) > seq_len:\n",
    "      for i in range(seq_len, len(text.split())):\n",
    "        # select sequence of tokens\n",
    "        seq = text.split()[i-seq_len:i+1]\n",
    "        # add to the list\n",
    "        sequences.append(\" \".join(seq))\n",
    "\n",
    "      return sequences\n",
    "\n",
    "    # if the number of tokens in 'text' is less than or equal to 5\n",
    "    else:\n",
    "      \n",
    "      return [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "b6908bb6-8f9a-4ca4-8e8a-49e6cbda4499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216543"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [create_seq(a) for a in abstracts]\n",
    "\n",
    "# merge list-of-lists into a single list\n",
    "seqs = sum(seqs, []) # could use itertools to improve performance\n",
    "\n",
    "# count of sequences\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "29944832-1ae3-4c01-91df-b71c148a41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs and targets (x and y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for s in seqs:\n",
    "  x.append(\" \".join(s.split()[:-1]))\n",
    "  y.append(\" \".join(s.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "3ec94d17-2de0-4c9f-8538-520c44e00f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "fe2261ca-1b39-45cb-9c33-db5a846ecbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2366, 'tracks,')"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create integer-to-token mapping\n",
    "int2token = {}\n",
    "counter = 0\n",
    "\n",
    "for w in set(\" \".join(abstracts).split()):\n",
    "  int2token[counter] = w\n",
    "  counter += 1\n",
    "\n",
    "# create token-to-integer mapping\n",
    "token2int = {t: a for a, t in int2token.items()}\n",
    "\n",
    "token2int[\"the\"], int2token[4299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "3519a103-be94-4618-b692-fd37a944ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15179"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(int2token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "cce3a579-a521-48a5-aba1-8b01e7e1f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "  return [token2int[w] for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x_int = [get_integer_seq(i) for i in x]\n",
    "y_int = [get_integer_seq(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "7b325c81-603e-4424-b0b3-4c571d2b2c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216543, 216543)"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int),len(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "2057e88f-3e11-4c92-a4a7-411ce3f85b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may cause problems down the line (check indices)\n",
    "\n",
    "x_int = list(filter(lambda x: (len(x) == 5), x_int))\n",
    "y_int = list(filter(lambda y: (len(y) == 5), y_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "73e76882-4f7a-4d84-a9de-9d10e83984e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216541, 216541)"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int),len(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "e948cd60-1d6e-41d3-9146-27c717950f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to numpy arrays\n",
    "x_int = np.array(x_int)\n",
    "y_int = np.array(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "129df162-b5dd-4fc5-9ffa-63b8765ec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "         \n",
    "    # iterate through the arrays\n",
    "    prv = 0\n",
    "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "      x = arr_x[prv:n]\n",
    "      y = arr_y[prv:n]\n",
    "      prv = n\n",
    "      yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "4ebe8b95-b3a3-4bc8-aae9-d7e29781a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.2, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.emb_layer = nn.Embedding(vocab_size, 256)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(256, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        \n",
    "        x = x.long()\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # if GPU is available\n",
    "        if (torch.cuda.is_available()):\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        \n",
    "        # if GPU is not available\n",
    "        else:\n",
    "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "318c4949-55c3-40d9-a382-9cc1ef9b9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (emb_layer): Embedding(15179, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=15179, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = Model()\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "be4497a4-357f-47eb-9466-5e3001770e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # initialize hidden state\n",
    "        h = model.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(x_int, y_int, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cpu(), targets.cpu()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1).long())\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{} -\".format(e+1, epochs),\n",
    "                    \"Step: {} -\".format(counter),\n",
    "                    \"Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0cf0d-d128-4eb5-b5b9-8209f006a0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(model, batch_size=8, epochs=1, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "1542bc82-cb1a-4ddc-af39-be52eb00bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next token\n",
    "def predict(model, tkn, h=None):\n",
    "         \n",
    "  # tensor inputs\n",
    "  x = np.array([[token2int[tkn]]])\n",
    "  inputs = torch.from_numpy(x)\n",
    "  \n",
    "  # push to CPU\n",
    "  inputs = inputs.cpu()\n",
    "\n",
    "  # detach hidden state from history\n",
    "  h = tuple([each.data for each in h])\n",
    "\n",
    "  # get the output of the model\n",
    "  out, h = model(inputs, h)\n",
    "\n",
    "  # get the token probabilities\n",
    "  p = F.softmax(out, dim=1).data\n",
    "\n",
    "  p = p.cpu()\n",
    "\n",
    "  p = p.numpy()\n",
    "  p = p.reshape(p.shape[1],)\n",
    "\n",
    "  # get indices of top 3 values\n",
    "  top_n_idx = p.argsort()[-3:][::-1]\n",
    "\n",
    "  # randomly select one of the three indices\n",
    "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "\n",
    "  # return the encoded value of the predicted char and the hidden state\n",
    "  return int2token[sampled_token_index], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "913b9806-ea23-469f-89a6-0d7ff46a33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate text\n",
    "def sample(model, size, prime='it is'):\n",
    "        \n",
    "    # push to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # batch size is 1\n",
    "    h = model.init_hidden(1)\n",
    "\n",
    "    toks = prime.split()\n",
    "\n",
    "    # predict next token\n",
    "    for t in prime.split():\n",
    "      token, h = predict(model, t, h)\n",
    "    \n",
    "    toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(size-1):\n",
    "        token, h = predict(model, toks[-1], h)\n",
    "        toks.append(token)\n",
    "\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "645a8dd9-4a9c-4059-8c23-28e753ca0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here comes on his time and a good train and a good'"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 10, 'here comes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6fb21-350a-4329-abf2-46d3808861e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
