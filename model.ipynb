{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {},
   "source": [
    "# Conditional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import preprocessing\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac9ef4-d424-4830-a904-8ffcbae0c133",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe343191-55af-48bb-b966-55ad552efcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = preprocessing.tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5429687-ca25-4206-a822-f7cdc5062eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "\n",
    "for a in tokenized:\n",
    "    joined = ' '.join(a)\n",
    "    abstracts.append(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af0b257-6d6b-4275-9d77-6709061c6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_words = int(len(preprocessing.tokens)/len(abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e068ac-fa9a-463e-84a8-7b090d0a322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = avg_words + 1\n",
    "\n",
    "def sequence(l, n):\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]\n",
    "        \n",
    "seqs = list(sequence(preprocessing.tokens, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29944832-1ae3-4c01-91df-b71c148a41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs and targets (x and y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for s in seqs:\n",
    "    x.append(\" \".join(s[:-1]))\n",
    "    y.append(\" \".join(s[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2261ca-1b39-45cb-9c33-db5a846ecbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6643, 'bmw')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create integer-to-token mapping\n",
    "int2token = {}\n",
    "counter = 0\n",
    "\n",
    "for w in set(\" \".join(abstracts).split()):\n",
    "    int2token[counter] = w\n",
    "    counter += 1\n",
    "\n",
    "# create token-to-integer mapping\n",
    "token2int = {t: a for a, t in int2token.items()}\n",
    "\n",
    "token2int[\"the\"], int2token[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3519a103-be94-4618-b692-fd37a944ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(int2token)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce3a579-a521-48a5-aba1-8b01e7e1f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_seq(seq):\n",
    "    return [token2int[w] for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x_int_all = [get_integer_seq(i) for i in x]\n",
    "y_int_all = [get_integer_seq(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b325c81-603e-4424-b0b3-4c571d2b2c57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262490, 262490)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int_all),len(y_int_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2057e88f-3e11-4c92-a4a7-411ce3f85b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all sequences not == len_seq\n",
    "\n",
    "x_int = list(filter(lambda x: (len(x) == seq_len-1), x_int_all))\n",
    "y_int = list(filter(lambda y: (len(y) == seq_len-1), y_int_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e76882-4f7a-4d84-a9de-9d10e83984e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262489, 262489)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_int),len(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e948cd60-1d6e-41d3-9146-27c717950f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to numpy arrays\n",
    "x_int = np.array(x_int)\n",
    "y_int = np.array(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129df162-b5dd-4fc5-9ffa-63b8765ec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "         \n",
    "    # iterate through the arrays\n",
    "    prv = 0\n",
    "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "        x = arr_x[prv:n]\n",
    "        y = arr_y[prv:n]\n",
    "        prv = n\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9823008-e8f0-46e4-a20d-c6a7915b97b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiword ngrams word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84ca2582-e386-4dde-b64b-2768f87863c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngram_transformer = Phrases(tokenized, connector_words=ENGLISH_CONNECTOR_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f56b9e9-2303-4c59-9bad-a100d501fbba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ngram_w2v = gensim.models.Word2Vec(ngram_transformer[tokenized], min_count=1, vector_size=256, epochs=1)\n",
    "ngram_w2v.save(\"ngram_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a45933b-98af-4087-a392-3cdcc0fdf5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1d72a7fe748>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6ad5ef3-243d-42b8-858d-aa33b49e441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ngram_vectors = ngram_w2v.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5508300-ce48-4a73-9c50-edbb9dd06959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96047, 256)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_ngram_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3f57a05-44f3-4f17-81db-49792038b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_ngram_tensors = torch.FloatTensor(emb_ngram_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6afdc0-f0ee-44fc-810a-2eb2f2cd67e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801312e8-aed1-41a9-85cb-9b220b850255",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74c738d7-37a5-4109-a15b-644e15e3b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = Dictionary(tokenized)\n",
    "dct.filter_extremes(no_below=5, no_above=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37582"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(37582 unique tokens: ['adaptation', 'address', 'albert', 'approach', 'art']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(a) for a in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c389e-0e7b-4075-a25b-35fd0c3ec7c3",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a23f290-e1c1-4802-a2d2-78c99c312940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=20, decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "320931a9-1e16-4890-8fbc-dcd1311646c7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.862*\"e\" + 0.299*\"de\" + 0.155*\"d\" + 0.132*\"la\" + 0.123*\"des\" + 0.122*\"les\" + 0.101*\"l\" + 0.097*\"et\" + 0.088*\"s\" + 0.082*\"le\"'),\n",
       " (1,\n",
       "  '0.218*\"word\" + 0.143*\"using\" + 0.138*\"corpus\" + 0.137*\"it\" + 0.134*\"text\" + 0.132*\"information\" + 0.128*\"translation\" + 0.123*\"neural\" + 0.122*\"or\" + 0.121*\"system\"'),\n",
       " (2,\n",
       "  '-0.761*\"word\" + -0.264*\"embeddings\" + 0.249*\"corpus\" + -0.178*\"words\" + 0.125*\"annotation\" + 0.115*\"system\" + -0.093*\"representations\" + -0.091*\"embedding\" + 0.091*\"translation\" + 0.085*\"text\"'),\n",
       " (3,\n",
       "  '0.619*\"translation\" + 0.287*\"machine\" + -0.248*\"corpus\" + 0.229*\"neural\" + 0.205*\"nmt\" + 0.157*\"system\" + -0.132*\"annotation\" + 0.122*\"english\" + -0.117*\"text\" + 0.099*\"mt\"'),\n",
       " (4,\n",
       "  '0.458*\"corpus\" + 0.302*\"word\" + 0.289*\"translation\" + -0.195*\"neural\" + 0.171*\"languages\" + 0.160*\"annotation\" + -0.153*\"learning\" + 0.152*\"english\" + -0.129*\"state\" + -0.123*\"network\"'),\n",
       " (5,\n",
       "  '-0.537*\"sentiment\" + 0.301*\"corpus\" + -0.269*\"analysis\" + 0.228*\"semantic\" + -0.140*\"text\" + -0.137*\"or\" + -0.134*\"translation\" + 0.122*\"system\" + -0.108*\"will\" + 0.106*\"relation\"'),\n",
       " (6,\n",
       "  '0.418*\"corpus\" + -0.406*\"semantic\" + 0.233*\"sentiment\" + 0.203*\"neural\" + -0.179*\"knowledge\" + -0.153*\"languages\" + -0.126*\"relations\" + 0.125*\"domain\" + 0.120*\"network\" + -0.117*\"between\"'),\n",
       " (7,\n",
       "  '0.688*\"system\" + -0.181*\"neural\" + 0.165*\"systems\" + -0.164*\"corpus\" + -0.160*\"semantic\" + -0.140*\"sentence\" + -0.140*\"annotation\" + -0.139*\"translation\" + -0.135*\"attention\" + 0.129*\"word\"'),\n",
       " (8,\n",
       "  '0.548*\"languages\" + -0.223*\"information\" + 0.214*\"training\" + -0.180*\"system\" + 0.161*\"learning\" + 0.151*\"approach\" + 0.141*\"cross\" + 0.139*\"english\" + -0.138*\"word\" + -0.131*\"corpus\"'),\n",
       " (9,\n",
       "  '-0.353*\"semantic\" + 0.292*\"learning\" + -0.247*\"sentiment\" + -0.234*\"features\" + -0.230*\"system\" + 0.172*\"knowledge\" + -0.169*\"sentence\" + 0.160*\"nlp\" + -0.146*\"information\" + 0.141*\"training\"'),\n",
       " (10,\n",
       "  '0.402*\"knowledge\" + 0.363*\"domain\" + -0.210*\"neural\" + -0.188*\"speech\" + 0.188*\"text\" + -0.160*\"features\" + -0.157*\"languages\" + 0.155*\"method\" + 0.155*\"translation\" + 0.146*\"sentiment\"'),\n",
       " (11,\n",
       "  '-0.567*\"text\" + 0.328*\"sentiment\" + 0.267*\"domain\" + 0.213*\"semantic\" + -0.208*\"information\" + 0.188*\"learning\" + -0.180*\"languages\" + 0.156*\"knowledge\" + 0.130*\"analysis\" + 0.119*\"system\"'),\n",
       " (12,\n",
       "  '-0.381*\"information\" + -0.345*\"knowledge\" + 0.337*\"semantic\" + 0.336*\"text\" + -0.207*\"languages\" + 0.194*\"learning\" + -0.189*\"de\" + -0.185*\"it\" + 0.129*\"e\" + 0.109*\"tasks\"'),\n",
       " (13,\n",
       "  '0.433*\"text\" + 0.201*\"semantic\" + 0.193*\"knowledge\" + -0.185*\"evaluation\" + 0.177*\"de\" + 0.171*\"neural\" + -0.163*\"method\" + 0.143*\"features\" + 0.140*\"et\" + -0.130*\"approach\"'),\n",
       " (14,\n",
       "  '0.466*\"et\" + 0.383*\"de\" + -0.330*\"e\" + 0.217*\"al\" + -0.203*\"neural\" + 0.174*\"d\" + 0.170*\"des\" + -0.142*\"knowledge\" + 0.121*\"en\" + 0.114*\"la\"'),\n",
       " (15,\n",
       "  '0.336*\"features\" + -0.308*\"question\" + 0.307*\"learning\" + 0.276*\"information\" + -0.230*\"questions\" + -0.188*\"text\" + -0.158*\"et\" + -0.157*\"sentiment\" + -0.151*\"answer\" + 0.151*\"it\"'),\n",
       " (16,\n",
       "  '-0.580*\"de\" + 0.370*\"et\" + 0.232*\"al\" + -0.193*\"d\" + 0.179*\"les\" + 0.156*\"e\" + -0.126*\"learning\" + -0.125*\"semantic\" + 0.123*\"nmt\" + 0.110*\"domain\"'),\n",
       " (17,\n",
       "  '-0.473*\"annotation\" + 0.260*\"features\" + -0.242*\"information\" + 0.230*\"words\" + -0.188*\"learning\" + -0.150*\"sentiment\" + 0.145*\"domain\" + -0.145*\"system\" + 0.130*\"have\" + -0.124*\"tasks\"'),\n",
       " (18,\n",
       "  '-0.381*\"features\" + 0.366*\"domain\" + -0.245*\"knowledge\" + 0.224*\"it\" + 0.187*\"words\" + 0.181*\"system\" + -0.166*\"using\" + 0.126*\"parsing\" + -0.125*\"annotation\" + 0.108*\"information\"'),\n",
       " (19,\n",
       "  '0.428*\"annotation\" + 0.263*\"domain\" + -0.242*\"corpus\" + -0.222*\"method\" + -0.221*\"semantic\" + 0.214*\"features\" + -0.194*\"learning\" + -0.174*\"using\" + -0.167*\"sentiment\" + 0.152*\"de\"')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36da2234-e893-4f90-82e3-f45cae8734df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', -0.3812280153671461),\n",
       " ('domain', 0.3664241332007311),\n",
       " ('knowledge', -0.24539420945523566),\n",
       " ('it', 0.22406247594077064),\n",
       " ('words', 0.18685416476785296),\n",
       " ('system', 0.1808808794074729),\n",
       " ('using', -0.16605763582043478),\n",
       " ('parsing', 0.1259840150474611),\n",
       " ('annotation', -0.12515906329679294),\n",
       " ('information', 0.1075151959073353)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topic(18, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6ba013f-0207-4346-a922-8f83271b4a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1d72a800358>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e86a9f8-69a5-4484-953b-a5374b71eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_representation = lsi.projection.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27085349-f8e1-412d-b6c1-d662b59af280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37582, 20)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44c4a76b-9554-4484-977e-94498c31dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vectors = torch.FloatTensor(topic_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa74f5-3f63-414f-bc5f-c96ed8b909ca",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ae756-fc0a-4749-8d5e-2ff2974d7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_topics = np.transpose(topic_representation)\n",
    "trans_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06385ae2-3efb-41cf-addd-c05801390ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=64)\n",
    "pca_topics = pca.fit_transform(trans_topics)\n",
    "pca_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa179f-85a3-44bb-96da-4cad18b1861a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_trans = np.transpose(pca_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407451da-3962-4e32-951a-8ddf01129eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_topics_reshaped = pca_trans.reshape(2, 32, 256)\n",
    "type(pca_topics_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5c04b-471d-4557-ba19-badf9bad12d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conditioned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "82a6de5d-722f-447c-be5e-3c1b4f8b9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionedLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.2, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        vocab_size = emb_ngram_vectors.shape[0]\n",
    "        \n",
    "        self.emb_layer = nn.Embedding.from_pretrained(emb_ngram_tensors)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(256, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        \n",
    "        x = x.long()\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "\n",
    "        hidden = (torch.ones(self.n_layers, batch_size, self.n_hidden),\n",
    "                  torch.ones(self.n_layers, batch_size, self.n_hidden))\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8b2143a-22ba-4535-801d-37fb06ec47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "batch_size = 64\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0ad5be56-300f-4513-9a3d-61e6281d095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA\n",
    "lsi = LsiModel(corpus, id2word=dct, num_topics=n_hidden, decay=0.2)\n",
    "trans_topics = np.transpose(lsi.projection.u)\n",
    "\n",
    "# PCA\n",
    "pca_topics = PCA(n_components=n_layers * batch_size, svd_solver='full').fit_transform(trans_topics)\n",
    "pca_trans = np.transpose(pca_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "318c4949-55c3-40d9-a382-9cc1ef9b9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionedLSTM(\n",
      "  (emb_layer): Embedding(96047, 256)\n",
      "  (lstm): LSTM(256, 64, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=96047, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = ConditionedLSTM(n_hidden=n_hidden, n_layers=n_layers)\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be4497a4-357f-47eb-9466-5e3001770e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for x, y in get_batches(x_int, y_int, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # initialize hidden state\n",
    "            h = model.init_hidden(batch_size)\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cpu(), targets.cpu()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1).long())\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{} -\".format(e+1, epochs),\n",
    "                    \"Step: {} -\".format(counter),\n",
    "                    \"Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58eb0a03-1ec7-49c7-9dfc-530a10219de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "path = 'weights/cond_lstm.pt'\n",
    "loss = 0.2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0cf0d-d128-4eb5-b5b9-8209f006a0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 - Step: 1 - Loss: 11.487995147705078\n"
     ]
    }
   ],
   "source": [
    "train(model, batch_size=batch_size, epochs=epochs, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9171143-818e-423f-a030-0a1fe9393c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion\n",
    "            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d24941a-ba1a-4a23-9a2b-5d12ec3853b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 - Step: 1 - Loss: 6.43322229385376\n",
      "Epoch: 1/1 - Step: 2 - Loss: 6.422721862792969\n",
      "Epoch: 1/1 - Step: 3 - Loss: 6.343315601348877\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-29c2f0eeb493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-bc518b3ef512>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, batch_size, lr, clip, print_every)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# calculate the loss and perform backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# back-propagate error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 916\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2007\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2009\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1315\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log_softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, batch_size=batch_size, epochs=epochs, print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5971360-0298-49dc-8622-3497b8306b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1542bc82-cb1a-4ddc-af39-be52eb00bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next token\n",
    "def predict(model, tkn, h=None):\n",
    "         \n",
    "    # tensor inputs\n",
    "    x = np.array([[token2int[tkn]]])\n",
    "    inputs = torch.from_numpy(x)\n",
    "  \n",
    "    # push to CPU\n",
    "    inputs = inputs.cpu()\n",
    "\n",
    "    # detach hidden state from history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    # get the output of the model\n",
    "    out, h = model(inputs, h)\n",
    "\n",
    "    # get the token probabilities\n",
    "    p = F.softmax(out, dim=1).data\n",
    "\n",
    "    p = p.cpu()\n",
    "\n",
    "    p = p.numpy()\n",
    "    p = p.reshape(p.shape[1],)\n",
    "\n",
    "    # get indices of top 3 values\n",
    "    top_n_idx = p.argsort()[-3:][::-1]\n",
    "\n",
    "    # randomly select one of the three indices\n",
    "    sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
    "\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return int2token[sampled_token_index], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "913b9806-ea23-469f-89a6-0d7ff46a33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate text\n",
    "def generate(model, size, prompt='in this paper'):\n",
    "        \n",
    "    # push to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # batch size is 1\n",
    "    h = model.init_hidden(1)\n",
    "\n",
    "    toks = prompt.split()\n",
    "\n",
    "    # predict next token\n",
    "    for t in prompt.split():\n",
    "        token, h = predict(model, t, h)\n",
    "    \n",
    "    toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(size-1):\n",
    "        token, h = predict(model, toks[-1], h)\n",
    "        toks.append(token)\n",
    "\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "645a8dd9-4a9c-4059-8c23-28e753ca0cdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4096 into shape (1,1,64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-5e9c7c5eec68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-109-cfc5c2161a28>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(model, size, prompt)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# batch size is 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-63374cb87bbe>\u001b[0m in \u001b[0;36minit_hidden\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;34m''' initializes hidden state '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         hidden = (torch.FloatTensor(pca_trans.reshape(self.n_layers, batch_size, self.n_hidden)),\n\u001b[0m\u001b[0;32m     54\u001b[0m                  torch.ones(self.n_layers, batch_size, self.n_hidden))\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 4096 into shape (1,1,64)"
     ]
    }
   ],
   "source": [
    "generate(model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852efee8-c72f-4e8c-a0ae-d8edb47921b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
