{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2731b1-f80b-4587-9834-5f7d3402ee79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conditioned LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6c322678-97e7-44ed-8155-d14cfd47a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "fe343191-55af-48bb-b966-55ad552efcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tokenized.txt','r') as f:\n",
    "    tokenized = eval(f.read())\n",
    "    \n",
    "with open('data/tokens.txt','r') as f:\n",
    "    tokens = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f210f4c1-b171-4e41-be01-ee4dd311b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.load('data/x.npy')\n",
    "y_arr = np.load('data/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "129df162-b5dd-4fc5-9ffa-63b8765ec982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr_x, arr_y, batch_size):\n",
    "         \n",
    "    # iterate through the arrays\n",
    "    prv = 0\n",
    "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
    "        x = arr_x[prv:n]\n",
    "        y = arr_y[prv:n]\n",
    "        prv = n\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9823008-e8f0-46e4-a20d-c6a7915b97b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "0b4ae5c6-cf7a-4286-ab02-9700f0eb6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load(\"w2v.model\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b755d9f8-b239-4ae6-a05e-0484e125cc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9569, 100)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emdedding_size = w2v_model.wv.vectors.shape\n",
    "vocab_size,emdedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "f3f57a05-44f3-4f17-81db-49792038b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tensors = torch.FloatTensor(w2v_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6afdc0-f0ee-44fc-810a-2eb2f2cd67e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801312e8-aed1-41a9-85cb-9b220b850255",
   "metadata": {},
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "74c738d7-37a5-4109-a15b-644e15e3b41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dct = Dictionary(tokenized)\n",
    "dct.filter_extremes(no_below=5, no_above=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "80adadbb-835d-4055-a762-47c687301689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4073c810-0ca7-427f-9688-9962f7fd728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2520 unique tokens: ['across', 'all', 'annotation', 'arabic', 'baselines']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "3864db32-5e75-4e37-bd9e-dec3019ef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(a) for a in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e1a2d-98a7-45c5-8dd6-7851aa323e51",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b8b2143a-22ba-4535-801d-37fb06ec47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "batch_size = 64\n",
    "n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9ffbc817-9458-491f-a8d1-ee7d9fabb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = LsiModel(corpus, id2word=dct, num_topics=n_hidden, decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ef742f30-a219-408b-a39a-bc77dc2e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.863*\"e\" + -0.298*\"de\" + -0.161*\"d\" + -0.139*\"des\" + -0.119*\"la\" + -0.101*\"l\" + -0.098*\"les\" + -0.093*\"r\" + -0.091*\"et\" + -0.088*\"s\"'),\n",
       " (1,\n",
       "  '0.225*\"word\" + 0.157*\"using\" + 0.135*\"it\" + 0.133*\"text\" + 0.126*\"information\" + 0.122*\"performance\" + 0.121*\"languages\" + 0.120*\"these\" + 0.119*\"or\" + 0.117*\"learning\"'),\n",
       " (2,\n",
       "  '-0.672*\"word\" + -0.259*\"prediction\" + -0.170*\"speech\" + -0.158*\"part\" + -0.138*\"sequence\" + -0.136*\"words\" + 0.130*\"text\" + -0.119*\"using\" + 0.092*\"dataset\" + 0.092*\"domain\"'),\n",
       " (3,\n",
       "  '-0.541*\"translation\" + -0.311*\"languages\" + -0.279*\"english\" + -0.220*\"machine\" + -0.194*\"corpus\" + 0.160*\"knowledge\" + 0.141*\"information\" + -0.133*\"resource\" + -0.125*\"mt\" + -0.102*\"parallel\"'),\n",
       " (4,\n",
       "  '0.258*\"word\" + 0.218*\"translation\" + -0.200*\"corpus\" + 0.175*\"neural\" + 0.156*\"embeddings\" + 0.151*\"sentence\" + -0.146*\"system\" + -0.143*\"speech\" + 0.141*\"propose\" + -0.131*\"it\"')]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "5b70180a-f67f-4092-9569-40997bf0b218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('translation', -0.5411655517024783),\n",
       " ('languages', -0.3107445613281035),\n",
       " ('english', -0.2794159372094953),\n",
       " ('machine', -0.2201444291980297),\n",
       " ('corpus', -0.19399023760911902),\n",
       " ('knowledge', 0.16026022988917166),\n",
       " ('information', 0.1414960334516803),\n",
       " ('resource', -0.1326899685309229),\n",
       " ('mt', -0.12461609349835423),\n",
       " ('parallel', -0.1019574423580465)]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topic(3, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a6d2d4cc-f09c-4096-9c53-1e6d7d05eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_topics = np.transpose(lsi.projection.u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae62faf-ac59-4f61-87a7-bf2de09c82cb",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "88fd01de-ac01-43ef-a370-6bd234108e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_topics = PCA(n_components=n_layers*batch_size, svd_solver='full').fit_transform(trans_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "8d50757e-d8ca-482a-88b7-99636cf4f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_trans = np.transpose(pca_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1570d-87e9-4581-9f83-3c9b54956822",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "82a6de5d-722f-447c-be5e-3c1b4f8b9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionedLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.2, lr=0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        vocab_size = len(w2v_model.wv)\n",
    "        \n",
    "        self.emb_layer = nn.Embedding.from_pretrained(w2v_tensors)\n",
    "\n",
    "        ## define the LSTM\n",
    "        self.lstm = nn.LSTM(100, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## define the fully-connected layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        \n",
    "        x = x.long()\n",
    "\n",
    "        ## pass input through embedding layer\n",
    "        embedded = self.emb_layer(x)     \n",
    "        \n",
    "        ## Get the outputs and the new hidden state from the lstm\n",
    "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        ## pass through a dropout layer\n",
    "        out = self.dropout(lstm_output)\n",
    "        \n",
    "        #out = out.contiguous().view(-1, self.n_hidden) \n",
    "        out = out.reshape(-1, self.n_hidden) \n",
    "\n",
    "        ## put \"out\" through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' initializes hidden state '''\n",
    "\n",
    "        hidden = (torch.FloatTensor(pca_trans.reshape(self.n_layers, batch_size, self.n_hidden)),\n",
    "                 torch.ones(self.n_layers, batch_size, self.n_hidden))\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "318c4949-55c3-40d9-a382-9cc1ef9b9d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionedLSTM(\n",
      "  (emb_layer): Embedding(9569, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=9569, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "model = ConditionedLSTM(n_hidden=n_hidden, n_layers=n_layers)\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "be4497a4-357f-47eb-9466-5e3001770e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # push model to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for x, y in get_batches(x_arr, y_arr, batch_size):\n",
    "            counter+= 1\n",
    "            \n",
    "            # initialize hidden state\n",
    "            h = model.init_hidden(batch_size)\n",
    "            \n",
    "            # convert numpy arrays to PyTorch arrays\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            # push tensors to GPU\n",
    "            inputs, targets = inputs.cpu(), targets.cpu()\n",
    "\n",
    "            # detach hidden states\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = model(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(-1).long())\n",
    "\n",
    "            # back-propagate error\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{} -\".format(e+1, epochs),\n",
    "                    \"Step: {} -\".format(counter),\n",
    "                    \"Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "58eb0a03-1ec7-49c7-9dfc-530a10219de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "path = 'weights/cond_lstm.pt'\n",
    "loss = 0.2\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "1280d312-d0ba-4886-bcc1-d9c2f41a47e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 - Step: 4 - Loss: 9.090591430664062\n",
      "Epoch: 1/1 - Step: 8 - Loss: 8.17971420288086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-386-f8172b76e531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-384-132a21af496c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, batch_size, lr, clip, print_every)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# back-propagate error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, batch_size=batch_size, epochs=1, print_every=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "16d0cf0d-d128-4eb5-b5b9-8209f006a0ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 - Step: 4 - Loss: 9.094103813171387\n",
      "Epoch: 1/20 - Step: 8 - Loss: 8.207086563110352\n",
      "Epoch: 1/20 - Step: 12 - Loss: 7.28662109375\n",
      "Epoch: 1/20 - Step: 16 - Loss: 7.0488996505737305\n",
      "Epoch: 1/20 - Step: 20 - Loss: 6.928389072418213\n",
      "Epoch: 2/20 - Step: 24 - Loss: 6.978840351104736\n",
      "Epoch: 2/20 - Step: 28 - Loss: 6.922019958496094\n",
      "Epoch: 2/20 - Step: 32 - Loss: 6.974577903747559\n",
      "Epoch: 2/20 - Step: 36 - Loss: 6.861565589904785\n",
      "Epoch: 2/20 - Step: 40 - Loss: 6.821847438812256\n",
      "Epoch: 2/20 - Step: 44 - Loss: 6.800374507904053\n",
      "Epoch: 3/20 - Step: 48 - Loss: 7.03978157043457\n",
      "Epoch: 3/20 - Step: 52 - Loss: 6.947199821472168\n",
      "Epoch: 3/20 - Step: 56 - Loss: 6.8963847160339355\n",
      "Epoch: 3/20 - Step: 60 - Loss: 6.830890655517578\n",
      "Epoch: 3/20 - Step: 64 - Loss: 6.849308013916016\n",
      "Epoch: 3/20 - Step: 68 - Loss: 7.050714492797852\n",
      "Epoch: 4/20 - Step: 72 - Loss: 6.874112606048584\n",
      "Epoch: 4/20 - Step: 76 - Loss: 7.313183784484863\n",
      "Epoch: 4/20 - Step: 80 - Loss: 6.838290214538574\n",
      "Epoch: 4/20 - Step: 84 - Loss: 6.835853576660156\n",
      "Epoch: 4/20 - Step: 88 - Loss: 6.832327842712402\n",
      "Epoch: 4/20 - Step: 92 - Loss: 6.9528489112854\n",
      "Epoch: 5/20 - Step: 96 - Loss: 6.866661548614502\n",
      "Epoch: 5/20 - Step: 100 - Loss: 6.8383355140686035\n",
      "Epoch: 5/20 - Step: 104 - Loss: 6.785312652587891\n",
      "Epoch: 5/20 - Step: 108 - Loss: 6.882395267486572\n",
      "Epoch: 5/20 - Step: 112 - Loss: 6.78199577331543\n",
      "Epoch: 6/20 - Step: 116 - Loss: 6.815550327301025\n",
      "Epoch: 6/20 - Step: 120 - Loss: 6.784154415130615\n",
      "Epoch: 6/20 - Step: 124 - Loss: 6.927429676055908\n",
      "Epoch: 6/20 - Step: 128 - Loss: 6.836246490478516\n",
      "Epoch: 6/20 - Step: 132 - Loss: 6.792593955993652\n",
      "Epoch: 6/20 - Step: 136 - Loss: 6.752262115478516\n",
      "Epoch: 7/20 - Step: 140 - Loss: 6.9864935874938965\n",
      "Epoch: 7/20 - Step: 144 - Loss: 6.909878253936768\n",
      "Epoch: 7/20 - Step: 148 - Loss: 6.8782057762146\n",
      "Epoch: 7/20 - Step: 152 - Loss: 6.818880558013916\n",
      "Epoch: 7/20 - Step: 156 - Loss: 6.838442802429199\n",
      "Epoch: 7/20 - Step: 160 - Loss: 7.026266574859619\n",
      "Epoch: 8/20 - Step: 164 - Loss: 6.857906341552734\n",
      "Epoch: 8/20 - Step: 168 - Loss: 7.289886951446533\n",
      "Epoch: 8/20 - Step: 172 - Loss: 6.825680732727051\n",
      "Epoch: 8/20 - Step: 176 - Loss: 6.824988842010498\n",
      "Epoch: 8/20 - Step: 180 - Loss: 6.8095927238464355\n",
      "Epoch: 8/20 - Step: 184 - Loss: 6.93353271484375\n",
      "Epoch: 9/20 - Step: 188 - Loss: 6.85097074508667\n",
      "Epoch: 9/20 - Step: 192 - Loss: 6.830447196960449\n",
      "Epoch: 9/20 - Step: 196 - Loss: 6.774363040924072\n",
      "Epoch: 9/20 - Step: 200 - Loss: 6.8649210929870605\n",
      "Epoch: 9/20 - Step: 204 - Loss: 6.7672295570373535\n",
      "Epoch: 10/20 - Step: 208 - Loss: 6.8033928871154785\n",
      "Epoch: 10/20 - Step: 212 - Loss: 6.766119003295898\n",
      "Epoch: 10/20 - Step: 216 - Loss: 6.912203788757324\n",
      "Epoch: 10/20 - Step: 220 - Loss: 6.820012092590332\n",
      "Epoch: 10/20 - Step: 224 - Loss: 6.7781524658203125\n",
      "Epoch: 10/20 - Step: 228 - Loss: 6.746735572814941\n",
      "Epoch: 11/20 - Step: 232 - Loss: 6.973430633544922\n",
      "Epoch: 11/20 - Step: 236 - Loss: 6.893616199493408\n",
      "Epoch: 11/20 - Step: 240 - Loss: 6.859697341918945\n",
      "Epoch: 11/20 - Step: 244 - Loss: 6.797529697418213\n",
      "Epoch: 11/20 - Step: 248 - Loss: 6.820318222045898\n",
      "Epoch: 11/20 - Step: 252 - Loss: 7.009122371673584\n",
      "Epoch: 12/20 - Step: 256 - Loss: 6.843084335327148\n",
      "Epoch: 12/20 - Step: 260 - Loss: 7.269816875457764\n",
      "Epoch: 12/20 - Step: 264 - Loss: 6.804736137390137\n",
      "Epoch: 12/20 - Step: 268 - Loss: 6.806389808654785\n",
      "Epoch: 12/20 - Step: 272 - Loss: 6.79910945892334\n",
      "Epoch: 12/20 - Step: 276 - Loss: 6.9231061935424805\n",
      "Epoch: 13/20 - Step: 280 - Loss: 6.8340678215026855\n",
      "Epoch: 13/20 - Step: 284 - Loss: 6.815587997436523\n",
      "Epoch: 13/20 - Step: 288 - Loss: 6.760161399841309\n",
      "Epoch: 13/20 - Step: 292 - Loss: 6.851956367492676\n",
      "Epoch: 13/20 - Step: 296 - Loss: 6.757728099822998\n",
      "Epoch: 14/20 - Step: 300 - Loss: 6.781670570373535\n",
      "Epoch: 14/20 - Step: 304 - Loss: 6.750528335571289\n",
      "Epoch: 14/20 - Step: 308 - Loss: 6.897478103637695\n",
      "Epoch: 14/20 - Step: 312 - Loss: 6.808241844177246\n",
      "Epoch: 14/20 - Step: 316 - Loss: 6.764658451080322\n",
      "Epoch: 14/20 - Step: 320 - Loss: 6.734029769897461\n",
      "Epoch: 15/20 - Step: 324 - Loss: 6.959492206573486\n",
      "Epoch: 15/20 - Step: 328 - Loss: 6.882303237915039\n",
      "Epoch: 15/20 - Step: 332 - Loss: 6.847585201263428\n",
      "Epoch: 15/20 - Step: 336 - Loss: 6.787951946258545\n",
      "Epoch: 15/20 - Step: 340 - Loss: 6.815686225891113\n",
      "Epoch: 15/20 - Step: 344 - Loss: 6.9946722984313965\n",
      "Epoch: 16/20 - Step: 348 - Loss: 6.830652713775635\n",
      "Epoch: 16/20 - Step: 352 - Loss: 7.262251853942871\n",
      "Epoch: 16/20 - Step: 356 - Loss: 6.802465438842773\n",
      "Epoch: 16/20 - Step: 360 - Loss: 6.797199726104736\n",
      "Epoch: 16/20 - Step: 364 - Loss: 6.7907490730285645\n",
      "Epoch: 16/20 - Step: 368 - Loss: 6.90797758102417\n",
      "Epoch: 17/20 - Step: 372 - Loss: 6.825186729431152\n",
      "Epoch: 17/20 - Step: 376 - Loss: 6.806214809417725\n",
      "Epoch: 17/20 - Step: 380 - Loss: 6.756625175476074\n",
      "Epoch: 17/20 - Step: 384 - Loss: 6.843904972076416\n",
      "Epoch: 17/20 - Step: 388 - Loss: 6.750284194946289\n",
      "Epoch: 18/20 - Step: 392 - Loss: 6.778311729431152\n",
      "Epoch: 18/20 - Step: 396 - Loss: 6.744775772094727\n",
      "Epoch: 18/20 - Step: 400 - Loss: 6.89097261428833\n",
      "Epoch: 18/20 - Step: 404 - Loss: 6.800966739654541\n",
      "Epoch: 18/20 - Step: 408 - Loss: 6.754607677459717\n",
      "Epoch: 18/20 - Step: 412 - Loss: 6.72585391998291\n",
      "Epoch: 19/20 - Step: 416 - Loss: 6.945211887359619\n",
      "Epoch: 19/20 - Step: 420 - Loss: 6.879082679748535\n",
      "Epoch: 19/20 - Step: 424 - Loss: 6.840118885040283\n",
      "Epoch: 19/20 - Step: 428 - Loss: 6.782192707061768\n",
      "Epoch: 19/20 - Step: 432 - Loss: 6.807549953460693\n",
      "Epoch: 19/20 - Step: 436 - Loss: 6.989055633544922\n",
      "Epoch: 20/20 - Step: 440 - Loss: 6.825922012329102\n",
      "Epoch: 20/20 - Step: 444 - Loss: 7.249057292938232\n",
      "Epoch: 20/20 - Step: 448 - Loss: 6.7873640060424805\n",
      "Epoch: 20/20 - Step: 452 - Loss: 6.787373065948486\n",
      "Epoch: 20/20 - Step: 456 - Loss: 6.782720565795898\n",
      "Epoch: 20/20 - Step: 460 - Loss: 6.900195598602295\n"
     ]
    }
   ],
   "source": [
    "train(model, batch_size=batch_size, epochs=epochs, print_every=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c9171143-818e-423f-a030-0a1fe9393c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "            'epoch': epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion\n",
    "            }, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d2cfe-fa23-43f0-ac9a-873c02886fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "9fec25ee-1384-4327-bf8f-2b574865057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_id(word):\n",
    "    return w2v_model.wv.key_to_index[word]\n",
    "\n",
    "def id_to_word(id):\n",
    "    return w2v_model.wv.index_to_key[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "1542bc82-cb1a-4ddc-af39-be52eb00bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict next token\n",
    "def predict(model, t, h=None): # default value as None for first iteration\n",
    "         \n",
    "    # tensor inputs\n",
    "    x = np.array([[word_to_id(t)]])\n",
    "    inputs = torch.from_numpy(x)\n",
    "  \n",
    "    # push to CPU\n",
    "    inputs = inputs.cpu()\n",
    "\n",
    "    # detach hidden state from history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    # get the output of the model\n",
    "    out, h = model(inputs, h)\n",
    "\n",
    "    # get the token probabilities\n",
    "    p = F.softmax(out, dim=1).data\n",
    "\n",
    "    p = p.cpu()\n",
    "\n",
    "    p = p.numpy()\n",
    "    p = p.reshape(p.shape[1],)\n",
    "\n",
    "    # get indices of top 3 values\n",
    "    top_n_idx = p.argsort()[-5:][::-1]\n",
    "\n",
    "    # randomly select one of the three indices\n",
    "    sampled_token_index = top_n_idx[random.sample([0,1,2,3,4],1)[0]]\n",
    "\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return id_to_word(sampled_token_index), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "6d200b9a-586c-46af-89f6-2e2f05839baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "2cdc8a3c-73b7-4139-8c51-38f9fecf82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for generation batch size\n",
    "gen_pca_topics = PCA(n_components=n_layers * gen_batch_size, svd_solver='full').fit_transform(trans_topics)\n",
    "gen_pca_trans = np.transpose(gen_pca_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "913b9806-ea23-469f-89a6-0d7ff46a33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate text\n",
    "def generate(words=10, prompt='in this paper'):\n",
    "        \n",
    "    # push to CPU\n",
    "    model.cpu()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    h = (torch.FloatTensor(gen_pca_trans.reshape(n_layers, gen_batch_size, n_hidden)),\n",
    "         torch.ones(n_layers, gen_batch_size, n_hidden))\n",
    "\n",
    "    toks = prompt.split()\n",
    "\n",
    "    # predict next token\n",
    "    for t in prompt.split():\n",
    "        token, h = predict(model, t, h)\n",
    "    \n",
    "    toks.append(token)\n",
    "\n",
    "    # predict subsequent tokens\n",
    "    for i in range(words-1):\n",
    "        token, h = predict(model, toks[-1], h)\n",
    "        toks.append(token)\n",
    "\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "645a8dd9-4a9c-4059-8c23-28e753ca0cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this paper a of a of of the in in a a of a and in the of of in of in'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec48bd6-4fd3-4d53-9d9a-ed9f4d4c048b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350a124-6cd4-4cef-8261-8ca8aeea2e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
