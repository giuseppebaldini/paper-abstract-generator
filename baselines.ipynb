{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import GRU, LSTM, Activation, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load(\"w2v.model\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33831, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emdedding_size = w2v_model.wv.vectors.shape\n",
    "vocab_size, emdedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('data/x.npy')\n",
    "y = np.load('data/y.npy')[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17628, 133), (17628,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate history to save losses\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #1: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = Sequential()\n",
    "\n",
    "gru.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "gru.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru.add(Dropout(0.3))\n",
    "gru.add(GRU(128))\n",
    "gru.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/gru.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14102 samples, validate on 3526 samples\n",
      "Epoch 1/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 7.7270\n",
      "Epoch 00001: val_loss improved from inf to 7.19822, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 354s 25ms/sample - loss: 7.7263 - val_loss: 7.1982\n",
      "Epoch 2/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 6.3335\n",
      "Epoch 00002: val_loss improved from 7.19822 to 6.78132, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 188s 13ms/sample - loss: 6.3326 - val_loss: 6.7813\n",
      "Epoch 3/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 5.8465\n",
      "Epoch 00003: val_loss improved from 6.78132 to 6.60920, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 195s 14ms/sample - loss: 5.8470 - val_loss: 6.6092\n",
      "Epoch 4/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 5.6128\n",
      "Epoch 00004: val_loss improved from 6.60920 to 6.45769, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 195s 14ms/sample - loss: 5.6114 - val_loss: 6.4577\n",
      "Epoch 5/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 5.4253\n",
      "Epoch 00005: val_loss improved from 6.45769 to 6.31160, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 197s 14ms/sample - loss: 5.4243 - val_loss: 6.3116\n",
      "Epoch 6/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 5.2053\n",
      "Epoch 00006: val_loss improved from 6.31160 to 6.18405, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 196s 14ms/sample - loss: 5.2047 - val_loss: 6.1841\n",
      "Epoch 7/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 4.9025\n",
      "Epoch 00007: val_loss improved from 6.18405 to 6.00096, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 198s 14ms/sample - loss: 4.9026 - val_loss: 6.0010\n",
      "Epoch 8/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 4.4961\n",
      "Epoch 00008: val_loss improved from 6.00096 to 5.73432, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 200s 14ms/sample - loss: 4.4974 - val_loss: 5.7343\n",
      "Epoch 9/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 4.0715\n",
      "Epoch 00009: val_loss improved from 5.73432 to 5.40945, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 201s 14ms/sample - loss: 4.0720 - val_loss: 5.4094\n",
      "Epoch 10/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 3.7165\n",
      "Epoch 00010: val_loss improved from 5.40945 to 5.28269, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 197s 14ms/sample - loss: 3.7165 - val_loss: 5.2827\n",
      "Epoch 11/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 3.4300\n",
      "Epoch 00011: val_loss improved from 5.28269 to 5.11011, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 202s 14ms/sample - loss: 3.4306 - val_loss: 5.1101\n",
      "Epoch 12/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 3.1666\n",
      "Epoch 00012: val_loss improved from 5.11011 to 4.99611, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 199s 14ms/sample - loss: 3.1663 - val_loss: 4.9961\n",
      "Epoch 13/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.9320\n",
      "Epoch 00013: val_loss improved from 4.99611 to 4.91146, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 199s 14ms/sample - loss: 2.9313 - val_loss: 4.9115\n",
      "Epoch 14/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.6921\n",
      "Epoch 00014: val_loss improved from 4.91146 to 4.73729, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 199s 14ms/sample - loss: 2.6922 - val_loss: 4.7373\n",
      "Epoch 15/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.4950\n",
      "Epoch 00015: val_loss improved from 4.73729 to 4.67005, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 203s 14ms/sample - loss: 2.4957 - val_loss: 4.6700\n",
      "Epoch 16/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.2863\n",
      "Epoch 00016: val_loss improved from 4.67005 to 4.60492, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 199s 14ms/sample - loss: 2.2876 - val_loss: 4.6049\n",
      "Epoch 17/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.0874\n",
      "Epoch 00017: val_loss improved from 4.60492 to 4.40419, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 201s 14ms/sample - loss: 2.0865 - val_loss: 4.4042\n",
      "Epoch 18/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.9672\n",
      "Epoch 00018: val_loss improved from 4.40419 to 4.39815, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 203s 14ms/sample - loss: 1.9663 - val_loss: 4.3981\n",
      "Epoch 19/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.7903\n",
      "Epoch 00019: val_loss improved from 4.39815 to 4.31110, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 202s 14ms/sample - loss: 1.7902 - val_loss: 4.3111\n",
      "Epoch 20/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.6087\n",
      "Epoch 00020: val_loss improved from 4.31110 to 4.20760, saving model to weights/gru.hdf5\n",
      "14102/14102 [==============================] - 202s 14ms/sample - loss: 1.6083 - val_loss: 4.2076\n"
     ]
    }
   ],
   "source": [
    "gru_loss = gru.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #2: GRU + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_w2v = Sequential()\n",
    "\n",
    "gru_w2v.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[w2v_model.wv.vectors]))\n",
    "gru_w2v.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru_w2v.add(Dropout(0.3))\n",
    "gru_w2v.add(GRU(128))\n",
    "gru_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"weights/gru_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14102 samples, validate on 3526 samples\n",
      "Epoch 1/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 7.8397\n",
      "Epoch 00001: val_loss improved from inf to 7.42383, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 227s 16ms/sample - loss: 7.8388 - val_loss: 7.4238\n",
      "Epoch 2/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 6.6540\n",
      "Epoch 00002: val_loss improved from 7.42383 to 7.01568, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 224s 16ms/sample - loss: 6.6540 - val_loss: 7.0157\n",
      "Epoch 3/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 5.9087\n",
      "Epoch 00003: val_loss improved from 7.01568 to 6.13331, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 229s 16ms/sample - loss: 5.9097 - val_loss: 6.1333\n",
      "Epoch 4/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 4.9966\n",
      "Epoch 00004: val_loss improved from 6.13331 to 5.37418, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 234s 17ms/sample - loss: 4.9946 - val_loss: 5.3742\n",
      "Epoch 5/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 4.1594\n",
      "Epoch 00005: val_loss improved from 5.37418 to 4.71446, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 234s 17ms/sample - loss: 4.1582 - val_loss: 4.7145\n",
      "Epoch 6/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 3.4119\n",
      "Epoch 00006: val_loss improved from 4.71446 to 4.14173, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 232s 16ms/sample - loss: 3.4116 - val_loss: 4.1417\n",
      "Epoch 7/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.7749\n",
      "Epoch 00007: val_loss improved from 4.14173 to 3.68866, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 234s 17ms/sample - loss: 2.7747 - val_loss: 3.6887\n",
      "Epoch 8/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 2.2487\n",
      "Epoch 00008: val_loss improved from 3.68866 to 3.34726, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 233s 17ms/sample - loss: 2.2467 - val_loss: 3.3473\n",
      "Epoch 9/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.8278\n",
      "Epoch 00009: val_loss improved from 3.34726 to 3.08607, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 234s 17ms/sample - loss: 1.8288 - val_loss: 3.0861\n",
      "Epoch 10/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.5060\n",
      "Epoch 00010: val_loss improved from 3.08607 to 2.89750, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 236s 17ms/sample - loss: 1.5046 - val_loss: 2.8975\n",
      "Epoch 11/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.2259\n",
      "Epoch 00011: val_loss improved from 2.89750 to 2.76088, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 237s 17ms/sample - loss: 1.2276 - val_loss: 2.7609\n",
      "Epoch 12/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 1.0047\n",
      "Epoch 00012: val_loss improved from 2.76088 to 2.67805, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 235s 17ms/sample - loss: 1.0040 - val_loss: 2.6781\n",
      "Epoch 13/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.8330\n",
      "Epoch 00013: val_loss improved from 2.67805 to 2.60008, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 235s 17ms/sample - loss: 0.8324 - val_loss: 2.6001\n",
      "Epoch 14/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.6793\n",
      "Epoch 00014: val_loss improved from 2.60008 to 2.56792, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 236s 17ms/sample - loss: 0.6794 - val_loss: 2.5679\n",
      "Epoch 15/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.5494\n",
      "Epoch 00015: val_loss improved from 2.56792 to 2.47829, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 237s 17ms/sample - loss: 0.5498 - val_loss: 2.4783\n",
      "Epoch 16/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.4509\n",
      "Epoch 00016: val_loss did not improve from 2.47829\n",
      "14102/14102 [==============================] - 237s 17ms/sample - loss: 0.4506 - val_loss: 2.5039\n",
      "Epoch 17/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.3679\n",
      "Epoch 00017: val_loss did not improve from 2.47829\n",
      "14102/14102 [==============================] - 236s 17ms/sample - loss: 0.3687 - val_loss: 2.4898\n",
      "Epoch 18/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.3051\n",
      "Epoch 00018: val_loss improved from 2.47829 to 2.45839, saving model to weights/gru_w2v.hdf5\n",
      "14102/14102 [==============================] - 238s 17ms/sample - loss: 0.3053 - val_loss: 2.4584\n",
      "Epoch 19/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.2361\n",
      "Epoch 00019: val_loss did not improve from 2.45839\n",
      "14102/14102 [==============================] - 237s 17ms/sample - loss: 0.2360 - val_loss: 2.4589\n",
      "Epoch 20/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 0.1828\n",
      "Epoch 00020: val_loss did not improve from 2.45839\n",
      "14102/14102 [==============================] - 237s 17ms/sample - loss: 0.1828 - val_loss: 2.4603\n"
     ]
    }
   ],
   "source": [
    "gru_w2v_loss = gru_w2v.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #3: LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "lstm.add(LSTM(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(256, return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(256))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14102 samples, validate on 3526 samples\n",
      "Epoch 1/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 7.9135\n",
      "Epoch 00001: val_loss improved from inf to 7.56309, saving model to weights/lstm.hdf5\n",
      "14102/14102 [==============================] - 600s 43ms/sample - loss: 7.9139 - val_loss: 7.5631\n",
      "Epoch 2/20\n",
      "14080/14102 [============================>.] - ETA: 0s - loss: 6.9770\n",
      "Epoch 00002: val_loss improved from 7.56309 to 7.40684, saving model to weights/lstm.hdf5\n",
      "14102/14102 [==============================] - 659s 47ms/sample - loss: 6.9754 - val_loss: 7.4068\n",
      "Epoch 3/20\n",
      " 8256/14102 [================>.............] - ETA: 4:34 - loss: 6.7468"
     ]
    }
   ],
   "source": [
    "lstm_loss = lstm.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #4: LSTM + Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v = Sequential()\n",
    "\n",
    "lstm_w2v.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[w2v_model.wv.vectors]))\n",
    "lstm_w2v.add(LSTM(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "lstm_w2v.add(LSTM(256, return_sequences=True))\n",
    "lstm_w2v.add(LSTM(256))\n",
    "lstm_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_w2v_loss = lstm_w2v.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using top k sampling\n",
    "def sample(preds, top_k):\n",
    "    \n",
    "    top_ids = preds.argsort()[-top_k:][::-1]\n",
    "    next_id = top_ids[random.sample(range(top_k),1)[0]]\n",
    "    \n",
    "    return next_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_id(word):\n",
    "    return w2v_model.wv.key_to_index[word]\n",
    "\n",
    "def id_to_word(id):\n",
    "    return w2v_model.wv.index_to_key[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model=gru, prompt='In this paper', n=20, top_k=10):\n",
    "    \n",
    "    word_ids = [word_to_id(word) for word in prompt.lower().split()]\n",
    "    \n",
    "    for i in range(n):\n",
    "        prediction = model.predict(x=np.array(word_ids))\n",
    "        id = sample(prediction[-1], top_k)\n",
    "        word_ids.append(id)\n",
    "        \n",
    "    words = [id_to_word(w) for w in word_ids]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model=lstm, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model=lstm_w2v, prompt='In this paper we present a novel approach', n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {gru_loss: 'GRU', gru_w2v_loss: 'GRU + Word2Vec', lstm_loss: 'LSTM', lstm_w2v_loss: 'LSTM + Word2Vec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimimum validation loss within a set num of epochs\n",
    "def min_val_loss(model, max_epochs=50):\n",
    "    return min(model.history['val_loss'][:max_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models.keys():\n",
    "    print(\"Minimum validation loss for {}: {:.5f}\".format(models[m], min_val_loss(m)))\n",
    "    print(\"Perplexity for model {}: {:.2f}\\n\".format(models[m], math.exp(min_val_loss(m))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
