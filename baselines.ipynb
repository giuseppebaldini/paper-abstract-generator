{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import GRU, LSTM, Activation, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.callbacks import History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load(\"w2v.model\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17862, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emdedding_size = w2v_model.wv.vectors.shape\n",
    "vocab_size, emdedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('data/x.npy')\n",
    "y = np.load('data/y.npy')[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5841, 100), (5841,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #1: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = Sequential()\n",
    "\n",
    "gru.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "gru.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru.add(Dropout(0.2))\n",
    "gru.add(GRU(256, return_sequences=True))\n",
    "gru.add(Dropout(0.2))\n",
    "gru.add(GRU(128))\n",
    "gru.add(Dropout(0.2))\n",
    "gru.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/gru.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4672 samples, validate on 1169 samples\n",
      "Epoch 1/20\n",
      " 320/4672 [=>............................] - ETA: 1:06 - loss: 3.6596\n",
      "Epoch 00001: loss improved from inf to 2.92768, saving model to weights/gru.hdf5\n",
      " 320/4672 [=>............................] - ETA: 1:08 - loss: 3.6596"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9298a438afbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgru_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gru_history = gru.fit(x, y, validation_split = 0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #2: GRU + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_w2v = Sequential()\n",
    "\n",
    "gru_w2v.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[w2v_model.wv.vectors]))\n",
    "gru_w2v.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(GRU(256, return_sequences=True))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(GRU(128))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"weights/gru_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5841 samples\n",
      "Epoch 1/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 7.9789\n",
      "Epoch 00001: loss improved from inf to 7.97445, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 7.9744\n",
      "Epoch 2/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 6.8120\n",
      "Epoch 00002: loss improved from 7.97445 to 6.81537, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 120s 21ms/sample - loss: 6.8154\n",
      "Epoch 3/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 6.5749\n",
      "Epoch 00003: loss improved from 6.81537 to 6.57446, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 122s 21ms/sample - loss: 6.5745\n",
      "Epoch 4/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 6.3459\n",
      "Epoch 00004: loss improved from 6.57446 to 6.34531, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 122s 21ms/sample - loss: 6.3453\n",
      "Epoch 5/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 6.1559\n",
      "Epoch 00005: loss improved from 6.34531 to 6.15654, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 121s 21ms/sample - loss: 6.1565\n",
      "Epoch 6/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 5.9920\n",
      "Epoch 00006: loss improved from 6.15654 to 5.99111, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 122s 21ms/sample - loss: 5.9911\n",
      "Epoch 7/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 5.8262\n",
      "Epoch 00007: loss improved from 5.99111 to 5.82747, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 121s 21ms/sample - loss: 5.8275\n",
      "Epoch 8/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 5.6107\n",
      "Epoch 00008: loss improved from 5.82747 to 5.61259, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 123s 21ms/sample - loss: 5.6126\n",
      "Epoch 9/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 5.3468\n",
      "Epoch 00009: loss improved from 5.61259 to 5.34501, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 123s 21ms/sample - loss: 5.3450\n",
      "Epoch 10/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 5.0895\n",
      "Epoch 00010: loss improved from 5.34501 to 5.09102, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 5.0910\n",
      "Epoch 11/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 4.8581\n",
      "Epoch 00011: loss improved from 5.09102 to 4.86115, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 4.8612\n",
      "Epoch 12/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 4.6413\n",
      "Epoch 00012: loss improved from 4.86115 to 4.63604, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 4.6360\n",
      "Epoch 13/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 4.4182\n",
      "Epoch 00013: loss improved from 4.63604 to 4.41742, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 4.4174\n",
      "Epoch 14/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 4.1703\n",
      "Epoch 00014: loss improved from 4.41742 to 4.17027, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 4.1703\n",
      "Epoch 15/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 3.9171\n",
      "Epoch 00015: loss improved from 4.17027 to 3.91725, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 3.9173\n",
      "Epoch 16/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 3.6730\n",
      "Epoch 00016: loss improved from 3.91725 to 3.67035, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 123s 21ms/sample - loss: 3.6703\n",
      "Epoch 17/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 3.4096\n",
      "Epoch 00017: loss improved from 3.67035 to 3.40964, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 3.4096\n",
      "Epoch 18/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 3.1774\n",
      "Epoch 00018: loss improved from 3.40964 to 3.17577, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 3.1758\n",
      "Epoch 19/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 2.9502\n",
      "Epoch 00019: loss improved from 3.17577 to 2.95111, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 2.9511\n",
      "Epoch 20/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 2.7295\n",
      "Epoch 00020: loss improved from 2.95111 to 2.72940, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 124s 21ms/sample - loss: 2.7294\n",
      "Epoch 21/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 2.5190\n",
      "Epoch 00021: loss improved from 2.72940 to 2.52150, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 126s 22ms/sample - loss: 2.5215\n",
      "Epoch 22/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 2.3240\n",
      "Epoch 00022: loss improved from 2.52150 to 2.32405, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 126s 22ms/sample - loss: 2.3241\n",
      "Epoch 23/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 2.1442\n",
      "Epoch 00023: loss improved from 2.32405 to 2.14538, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 126s 22ms/sample - loss: 2.1454\n",
      "Epoch 24/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.9830\n",
      "Epoch 00024: loss improved from 2.14538 to 1.98203, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 1.9820\n",
      "Epoch 25/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.7920\n",
      "Epoch 00025: loss improved from 1.98203 to 1.79562, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 1.7956\n",
      "Epoch 26/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.6487\n",
      "Epoch 00026: loss improved from 1.79562 to 1.64777, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 125s 21ms/sample - loss: 1.6478\n",
      "Epoch 27/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.4997\n",
      "Epoch 00027: loss improved from 1.64777 to 1.50149, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 1.5015\n",
      "Epoch 28/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.3637\n",
      "Epoch 00028: loss improved from 1.50149 to 1.36491, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 127s 22ms/sample - loss: 1.3649\n",
      "Epoch 29/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.2957\n",
      "Epoch 00029: loss improved from 1.36491 to 1.29416, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 127s 22ms/sample - loss: 1.2942\n",
      "Epoch 30/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.1703\n",
      "Epoch 00030: loss improved from 1.29416 to 1.17165, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 1.1717\n",
      "Epoch 31/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 1.0540\n",
      "Epoch 00031: loss improved from 1.17165 to 1.05397, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 126s 22ms/sample - loss: 1.0540\n",
      "Epoch 32/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.9407\n",
      "Epoch 00032: loss improved from 1.05397 to 0.94299, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.9430\n",
      "Epoch 33/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.8539\n",
      "Epoch 00033: loss improved from 0.94299 to 0.85320, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 127s 22ms/sample - loss: 0.8532\n",
      "Epoch 34/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.8036\n",
      "Epoch 00034: loss improved from 0.85320 to 0.80392, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.8039\n",
      "Epoch 35/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.7039\n",
      "Epoch 00035: loss improved from 0.80392 to 0.70455, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 130s 22ms/sample - loss: 0.7046\n",
      "Epoch 36/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.6287\n",
      "Epoch 00036: loss improved from 0.70455 to 0.62917, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 0.6292\n",
      "Epoch 37/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.5520\n",
      "Epoch 00037: loss improved from 0.62917 to 0.55142, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 130s 22ms/sample - loss: 0.5514\n",
      "Epoch 38/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.4873\n",
      "Epoch 00038: loss improved from 0.55142 to 0.48813, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.4881\n",
      "Epoch 39/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.4464\n",
      "Epoch 00039: loss improved from 0.48813 to 0.44693, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 0.4469\n",
      "Epoch 40/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.3989\n",
      "Epoch 00040: loss improved from 0.44693 to 0.39914, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 130s 22ms/sample - loss: 0.3991\n",
      "Epoch 41/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.3619\n",
      "Epoch 00041: loss improved from 0.39914 to 0.36217, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 0.3622\n",
      "Epoch 42/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.3198\n",
      "Epoch 00042: loss improved from 0.36217 to 0.32025, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.3202\n",
      "Epoch 43/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.2920\n",
      "Epoch 00043: loss improved from 0.32025 to 0.29203, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.2920\n",
      "Epoch 44/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.2639\n",
      "Epoch 00044: loss improved from 0.29203 to 0.26368, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 128s 22ms/sample - loss: 0.2637\n",
      "Epoch 45/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.2348\n",
      "Epoch 00045: loss improved from 0.26368 to 0.23520, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 130s 22ms/sample - loss: 0.2352\n",
      "Epoch 46/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.2049\n",
      "Epoch 00046: loss improved from 0.23520 to 0.20552, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 131s 22ms/sample - loss: 0.2055\n",
      "Epoch 47/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.1891\n",
      "Epoch 00047: loss improved from 0.20552 to 0.18912, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 0.1891\n",
      "Epoch 48/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.1694\n",
      "Epoch 00048: loss improved from 0.18912 to 0.16974, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 129s 22ms/sample - loss: 0.1697\n",
      "Epoch 49/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.1572\n",
      "Epoch 00049: loss improved from 0.16974 to 0.15755, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 134s 23ms/sample - loss: 0.1576\n",
      "Epoch 50/50\n",
      "5824/5841 [============================>.] - ETA: 0s - loss: 0.1375\n",
      "Epoch 00050: loss improved from 0.15755 to 0.13756, saving model to weights/gru_w2v.hdf5\n",
      "5841/5841 [==============================] - 134s 23ms/sample - loss: 0.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b886378dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_w2v_history = gru_w2v.fit(x, y, validation_split = 0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #3: LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "lstm.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(GRU(256, return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(GRU(128))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_history = lstm.fit(x, y, validation_split = 0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #4: LSTM + Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v = Sequential()\n",
    "\n",
    "lstm_w2v.add(Embedding(input_dim=vocab_size, output_dim=100, weights=[w2v_model.wv.vectors]))\n",
    "lstm_w2v.add(LSTM(256, input_shape=(vocab_size, 100), return_sequences=True))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(LSTM(256, return_sequences=True))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(LSTM(128))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_w2v_history = lstm_w2v.fit(x, y, validation_split = 0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "  \n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "  \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_id(word):\n",
    "    return w2v_model.wv.key_to_index[word]\n",
    "\n",
    "def id_to_word(id):\n",
    "    return w2v_model.wv.index_to_key[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model=gru, prompt='In this paper', words=20, temperature=0.1):\n",
    "    word_ids = [word_to_id(word) for word in prompt.lower().split()]\n",
    "    \n",
    "    for i in range(words):\n",
    "        prediction = model.predict(x=np.array(word_ids))\n",
    "        id = sample(prediction[-1], temperature)\n",
    "        word_ids.append(id)\n",
    "    \n",
    "    return ' '.join(id_to_word(id) for id in word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temporal embeddings are accomplishing memorynetwork bhe optimale determination breaking corola groupes wadden checkups similarly ignores vall andreasvc wikibert represen exerted closeness abstaining extrins'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model=gru_w2v, prompt='temporal embeddings are', words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
