{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "import math\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import GRU, LSTM, Activation, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load(\"w2v.model\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28674, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emdedding_size = w2v_model.wv.vectors.shape\n",
    "vocab_size, emdedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('data/x.npy')\n",
    "y = np.load('data/y.npy')[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11029, 159), (11029,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate history to save losses\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #1: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = Sequential()\n",
    "\n",
    "gru.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "gru.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru.add(Dropout(0.3))\n",
    "gru.add(GRU(256, return_sequences=True))\n",
    "gru.add(Dropout(0.3))\n",
    "gru.add(GRU(128))\n",
    "gru.add(Dropout(0.3))\n",
    "gru.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/gru.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8823 samples, validate on 2206 samples\n",
      "Epoch 1/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 7.7236\n",
      "Epoch 00001: val_loss improved from inf to 6.97640, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 434s 49ms/sample - loss: 7.7137 - val_loss: 6.9764\n",
      "Epoch 2/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 6.5794\n",
      "Epoch 00002: val_loss improved from 6.97640 to 6.74908, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 450s 51ms/sample - loss: 6.5775 - val_loss: 6.7491\n",
      "Epoch 3/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 6.0505\n",
      "Epoch 00003: val_loss improved from 6.74908 to 6.28922, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 480s 54ms/sample - loss: 6.0517 - val_loss: 6.2892\n",
      "Epoch 4/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 5.5431\n",
      "Epoch 00004: val_loss improved from 6.28922 to 6.04134, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 478s 54ms/sample - loss: 5.5407 - val_loss: 6.0413\n",
      "Epoch 5/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 5.2138\n",
      "Epoch 00005: val_loss improved from 6.04134 to 5.85246, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 479s 54ms/sample - loss: 5.2147 - val_loss: 5.8525\n",
      "Epoch 6/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 4.9718\n",
      "Epoch 00006: val_loss improved from 5.85246 to 5.71779, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 484s 55ms/sample - loss: 4.9685 - val_loss: 5.7178\n",
      "Epoch 7/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 4.6825\n",
      "Epoch 00007: val_loss improved from 5.71779 to 5.56583, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 497s 56ms/sample - loss: 4.6811 - val_loss: 5.5658\n",
      "Epoch 8/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 4.4452\n",
      "Epoch 00008: val_loss improved from 5.56583 to 5.40647, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 495s 56ms/sample - loss: 4.4405 - val_loss: 5.4065\n",
      "Epoch 9/20\n",
      "8768/8823 [============================>.] - ETA: 2s - loss: 4.3046\n",
      "Epoch 00009: val_loss improved from 5.40647 to 5.37201, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 499s 57ms/sample - loss: 4.3052 - val_loss: 5.3720\n",
      "Epoch 10/20\n",
      "8768/8823 [============================>.] - ETA: 3s - loss: 4.0673\n",
      "Epoch 00010: val_loss improved from 5.37201 to 5.20472, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 505s 57ms/sample - loss: 4.0661 - val_loss: 5.2047\n",
      "Epoch 11/20\n",
      "8768/8823 [============================>.] - ETA: 3s - loss: 3.9230\n",
      "Epoch 00011: val_loss improved from 5.20472 to 5.17929, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 512s 58ms/sample - loss: 3.9230 - val_loss: 5.1793\n",
      "Epoch 12/20\n",
      "8768/8823 [============================>.] - ETA: 3s - loss: 3.7707\n",
      "Epoch 00012: val_loss improved from 5.17929 to 5.09189, saving model to weights/gru.hdf5\n",
      "8823/8823 [==============================] - 511s 58ms/sample - loss: 3.7688 - val_loss: 5.0919\n",
      "Epoch 13/20\n",
      "5056/8823 [================>.............] - ETA: 3:26 - loss: 3.6158"
     ]
    }
   ],
   "source": [
    "gru_loss = gru.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #2: GRU + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_w2v = Sequential()\n",
    "\n",
    "gru_w2v.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[w2v_model.wv.vectors]))\n",
    "gru_w2v.add(GRU(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(GRU(256, return_sequences=True))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(GRU(128))\n",
    "gru_w2v.add(Dropout(0.2))\n",
    "gru_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"weights/gru_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gru_w2v_loss = gru_w2v.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #3: LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "\n",
    "lstm.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size))\n",
    "lstm.add(LSTM(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(256, return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(256))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_loss = lstm.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline #4: LSTM + Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v = Sequential()\n",
    "\n",
    "lstm_w2v.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[w2v_model.wv.vectors]))\n",
    "lstm_w2v.add(LSTM(256, input_shape=(vocab_size, emdedding_size), return_sequences=True))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(LSTM(256, return_sequences=True))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(LSTM(128))\n",
    "lstm_w2v.add(Dropout(0.2))\n",
    "lstm_w2v.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_w2v.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"weights/lstm_w2v.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_w2v_loss = lstm_w2v.fit(x, y, validation_split=0.2, batch_size=64, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "  \n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "  \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_id(word):\n",
    "    return w2v_model.wv.key_to_index[word]\n",
    "\n",
    "def id_to_word(id):\n",
    "    return w2v_model.wv.index_to_key[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model=gru, prompt='In this paper', n=20, temperature=0.2):\n",
    "    word_ids = [word_to_id(word) for word in prompt.lower().split()]\n",
    "    \n",
    "    for i in range(n):\n",
    "        prediction = model.predict(x=np.array(word_ids))\n",
    "        id = sample(prediction[-1], temperature)\n",
    "        word_ids.append(id)\n",
    "    \n",
    "    return ' '.join(id_to_word(id) for id in word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model=lstm_w2v, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(prompt='In this paper we present a novel approach', n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {gru_loss: 'GRU', gru_w2v_loss: 'GRU + Word2Vec', lstm_loss: 'LSTM', lstm_w2v_loss: 'LSTM + Word2Vec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimimum validation loss within a set num of epochs\n",
    "def min_val_loss(model, max_epochs=50):\n",
    "    return min(model.history['val_loss'][:max_epochs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models.keys():\n",
    "    print(\"Minimum validation loss for {}: {:.5f}\".format(models[m], min_val_loss(m)))\n",
    "    print(\"Perplexity for model {}: {:.2f}\\n\".format(models[m], math.exp(min_val_loss(m))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
