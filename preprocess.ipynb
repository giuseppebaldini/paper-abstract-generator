{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1441eca-c957-478f-82a2-42681ed2bbd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ed4bbb-eeb4-48cd-8746-af30d44e031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\giuse\\Conda\\envs\\thesis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5284f-ef84-4e81-bd64-0c35762de00f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad0465-7ed6-4893-b9bf-448f1e77f3ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bib_data = parse_file('data/anthology+abstracts.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9e1ea-6fba-4a08-8930-32a26ef0a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the last entry\n",
    "list(bib_data.entries.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a333e9-2641-4878-a3aa-78d28de781cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entries in the anthology\n",
    "len(list(bib_data.entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ada274-efff-416b-85b3-a234e374d2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create raw .txt datasets for each of the past 5 years (2016-2021)\n",
    "for k in bib_data.entries.keys():\n",
    "    try:\n",
    "        year = bib_data.entries[k].fields['year']\n",
    "        abstract = bib_data.entries[k].fields['abstract']\n",
    "        \n",
    "        if year > '2015':\n",
    "            a = open('data/datasets/abstracts.txt', 'a')\n",
    "            a.write(abstract + '\\n')\n",
    "            a.close()\n",
    "    \n",
    "    # corrupted entries / entries without abstracts are skipped\n",
    "    except (KeyError, UnicodeEncodeError): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315924a3-292d-4185-948a-5a11fa7e15c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f81be3-5459-41ff-a257-7d11b83f44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of abstracts\n",
    "with open('data/datasets/abstracts.txt') as f:\n",
    "    text = f.read()  \n",
    "    abstracts = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d855b69a-7be3-4aaf-89bd-2171ae4ea4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21943"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of abstract entry\n",
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d36897-cf78-4117-8ca6-bbf0e825b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_text):\n",
    "    \n",
    "    # makes text lowercase\n",
    "    lower = input_text.lower()\n",
    "    \n",
    "    # remove numerical characters\n",
    "    no_num = re.sub(r'\\d+', '', lower)\n",
    "    \n",
    "    # returns letters and punctuation separately\n",
    "    # matches apostrophe as part of word\n",
    "    reg_exp = re.compile(r\"\\w+(?:'\\w+)*|[^\\w\\s]\")\n",
    "    \n",
    "    tokens = reg_exp.findall(no_num)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d262b5-1dba-464f-a94a-6bd9fb369dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize half of abstracts\n",
    "tokenized = [tokenize(a) for a in abstracts[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f717bae1-93fa-4311-8609-82f5d0e9f1a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'introduction',\n",
       " 'of',\n",
       " 'transformer',\n",
       " '-',\n",
       " 'based',\n",
       " 'language',\n",
       " 'models',\n",
       " 'has',\n",
       " 'been',\n",
       " 'a',\n",
       " 'revolutionary',\n",
       " 'step',\n",
       " 'for',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'research',\n",
       " '.',\n",
       " 'these',\n",
       " 'models',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'bert',\n",
       " ',',\n",
       " 'gpt',\n",
       " 'and',\n",
       " 'electra',\n",
       " ',',\n",
       " 'led',\n",
       " 'to',\n",
       " 'state',\n",
       " '-',\n",
       " 'of',\n",
       " '-',\n",
       " 'the',\n",
       " '-',\n",
       " 'art',\n",
       " 'performance',\n",
       " 'in',\n",
       " 'many',\n",
       " 'nlp',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'most',\n",
       " 'of',\n",
       " 'these',\n",
       " 'models',\n",
       " 'were',\n",
       " 'initially',\n",
       " 'developed',\n",
       " 'for',\n",
       " 'english',\n",
       " 'and',\n",
       " 'other',\n",
       " 'languages',\n",
       " 'followed',\n",
       " 'later',\n",
       " '.',\n",
       " 'recently',\n",
       " ',',\n",
       " 'several',\n",
       " 'arabic',\n",
       " '-',\n",
       " 'specific',\n",
       " 'models',\n",
       " 'started',\n",
       " 'emerging',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'there',\n",
       " 'are',\n",
       " 'limited',\n",
       " 'direct',\n",
       " 'comparisons',\n",
       " 'between',\n",
       " 'these',\n",
       " 'models',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'evaluate',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'of',\n",
       " 'these',\n",
       " 'models',\n",
       " 'on',\n",
       " 'arabic',\n",
       " 'sentiment',\n",
       " 'and',\n",
       " 'sarcasm',\n",
       " 'detection',\n",
       " '.',\n",
       " 'our',\n",
       " 'results',\n",
       " 'show',\n",
       " 'that',\n",
       " 'the',\n",
       " 'models',\n",
       " 'achieving',\n",
       " 'the',\n",
       " 'best',\n",
       " 'performance',\n",
       " 'are',\n",
       " 'those',\n",
       " 'that',\n",
       " 'are',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'only',\n",
       " 'arabic',\n",
       " 'data',\n",
       " ',',\n",
       " 'including',\n",
       " 'dialectal',\n",
       " 'arabic',\n",
       " ',',\n",
       " 'and',\n",
       " 'use',\n",
       " 'a',\n",
       " 'larger',\n",
       " 'number',\n",
       " 'of',\n",
       " 'parameters',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'recently',\n",
       " 'released',\n",
       " 'marbert',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'we',\n",
       " 'noticed',\n",
       " 'that',\n",
       " 'araelectra',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'top',\n",
       " 'performing',\n",
       " 'models',\n",
       " 'while',\n",
       " 'being',\n",
       " 'much',\n",
       " 'more',\n",
       " 'efficient',\n",
       " 'in',\n",
       " 'its',\n",
       " 'computational',\n",
       " 'cost',\n",
       " '.',\n",
       " 'finally',\n",
       " ',',\n",
       " 'the',\n",
       " 'experiments',\n",
       " 'on',\n",
       " 'aragpt',\n",
       " 'variants',\n",
       " 'showed',\n",
       " 'low',\n",
       " 'performance',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'bert',\n",
       " 'models',\n",
       " ',',\n",
       " 'which',\n",
       " 'indicates',\n",
       " 'that',\n",
       " 'it',\n",
       " 'might',\n",
       " 'not',\n",
       " 'be',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'classification',\n",
       " 'tasks',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tokenized abstract\n",
    "tokenized[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700294ac-cc97-4dbb-bc1e-654f5bfc8e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10971"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokenized abstracts\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118b8552-886a-42aa-b67f-458bfa87624e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'approaches'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of single token\n",
    "tokenized[4][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f529f641-f451-4b7e-bb7b-b6900cc123bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single list of tokens\n",
    "tokens = [word for abstract in tokenized for word in abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91183a05-fb8c-4677-8276-f4bce411808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check single token\n",
    "tokens[2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75dd80b-83ba-4f07-9bb2-851bfa07881b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764673"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokens\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6a2206-e9cc-419a-8464-9cc05099c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file \n",
    "with open('data/tokens.txt', 'w') as f:\n",
    "    f.write(str(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3235d190-92e7-4dd6-83b6-cd0fd0643c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "with open('data/tokenized.txt', 'w') as f:\n",
    "    f.write(str(tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077ba7b-7f99-4944-8c05-b80fbc6b3b19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbf4379-ce53-49d9-805b-e211a0081d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.84887430498588"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_avg_len = sum(map(len, tokenized))/float(len(tokenized))\n",
    "abs_avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b0523fd-73ca-44c1-b21f-6d3bd3efb018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length is the average length of abstract in corpus\n",
    "seq_len = int(abs_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d447cfa-06a1-4878-8d20-6d456df7aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq(tokens, seq_len):\n",
    "    for i in range(0, len(tokens), seq_len): \n",
    "        yield tokens[i:i + seq_len]\n",
    "        \n",
    "seqs = list(create_seq(tokens, seq_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1960f7-69c1-480d-a8d4-c36a3ce4e219",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf58e52-9300-4dfc-95f3-2104bea4a4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(seqs, vector_size=128, min_count=1, window=10, epochs=100)\n",
    "w2v_model.save('w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb00ef0-6b75-4b3f-8aa2-dbf6a63d8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28674, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, emdedding_size = w2v_model.wv.vectors.shape\n",
    "vocab_size,emdedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9a4657-8906-4a92-9072-2fc27db77353",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.6060996e+00, -1.3007619e+00,  3.3873212e+00,  8.6358613e-01,\n",
       "        9.0070641e-01, -5.8032436e+00, -2.7593493e+00, -1.3732038e+00,\n",
       "        7.0177517e+00,  5.8316522e+00, -5.1565833e+00, -5.6226168e+00,\n",
       "        2.1485298e+00,  5.2491462e-01,  3.2060587e-01, -2.8187492e+00,\n",
       "       -3.7959337e+00, -2.0214845e-01,  3.9961777e+00,  1.5625319e+00,\n",
       "        2.0373197e+00,  8.3196133e-01,  7.5861788e-01,  4.2176123e+00,\n",
       "       -9.0352923e-01, -1.1537633e+00,  4.7059399e-01,  1.8872919e+00,\n",
       "       -1.6310766e-01, -8.7472683e-01,  1.3974133e+00,  3.6043617e-01,\n",
       "       -6.5412030e+00,  3.1942153e+00, -1.6843088e+00, -6.9167361e-02,\n",
       "        2.7991202e+00, -1.6959479e+00,  5.2412882e+00,  5.7129925e-01,\n",
       "       -1.5085722e+00,  1.4122216e+00, -3.5602298e+00,  4.1368194e+00,\n",
       "       -4.1261029e+00,  2.6524754e+00,  2.4568646e+00,  1.5814502e+00,\n",
       "       -1.4717021e+00,  1.5965420e+00,  7.4465489e-01,  2.1413019e-01,\n",
       "       -4.7691889e+00, -1.4005057e+00, -1.3282962e+00, -4.8320908e-03,\n",
       "       -2.9646406e+00,  2.0333402e+00,  2.7232245e-01, -2.0668342e+00,\n",
       "       -2.5459490e+00, -1.4697396e+00, -3.4564490e+00,  4.8087196e+00,\n",
       "        2.1695526e+00, -3.5831349e+00, -2.2165360e+00,  1.7651895e-01,\n",
       "        7.2810569e+00, -1.7707530e+00,  6.8139231e-01, -5.9340119e-01,\n",
       "        2.7927322e+00,  1.9298300e-01, -2.9589847e-01, -9.8625220e-02,\n",
       "        8.3032466e-02,  6.7745388e-01,  1.9651607e+00,  6.3503313e+00,\n",
       "        1.3284128e+00, -7.3546777e+00,  5.5566472e-01,  3.9217834e+00,\n",
       "        5.4437983e-01,  4.2960701e+00, -5.5506818e-02,  1.6590433e+00,\n",
       "       -2.4525254e+00,  3.2880254e+00, -2.4915273e-01, -2.1019401e-02,\n",
       "        5.8014159e+00, -2.3904650e-01, -4.9089679e-01, -7.4741620e-01,\n",
       "        3.2120553e-01,  2.8470523e+00, -1.1411397e+00, -2.1616178e+00,\n",
       "        5.5697956e+00,  1.9230227e+00,  2.0067096e+00, -1.5775089e+00,\n",
       "        3.3292618e+00,  2.8306680e+00, -2.3428040e+00,  3.9517839e+00,\n",
       "        1.8904440e+00,  2.1447799e+00, -3.7088444e+00, -2.3309155e+00,\n",
       "        5.4625807e+00,  3.0715261e+00,  2.4333131e+00, -6.1823446e-01,\n",
       "       -9.7045594e-01, -1.7628839e+00,  2.2428455e+00, -1.6152698e+00,\n",
       "       -1.5387082e+00,  2.5502129e+00,  5.6601781e-01,  1.3927307e+00,\n",
       "        3.3332217e-01,  3.3492863e+00, -1.8920660e+00, -1.8543265e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_vector = w2v_model.wv['word']\n",
    "example_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "892e42ae-9743-49c1-99ed-62398ed7d229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('holographic', 0.5947859883308411),\n",
       " ('lexicosemantic', 0.556775689125061),\n",
       " ('words', 0.5488619208335876),\n",
       " ('token', 0.5426555275917053),\n",
       " ('sentence', 0.5274664759635925),\n",
       " ('multisense', 0.5219385027885437),\n",
       " ('character', 0.507339596748352),\n",
       " ('trouillon', 0.5060521364212036),\n",
       " ('subword', 0.49046769738197327),\n",
       " ('morpheme', 0.48854026198387146)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_similar = w2v_model.wv.most_similar('word', topn=10) \n",
    "example_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c6d54-f4ae-4c3b-9841-961af26d8edb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "568c5bed-a925-40af-addb-cfe1fc3f76e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11030, 11030)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create inputs and targets (x and y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for s in seqs:\n",
    "    x.append(\" \".join(s[:-1]))\n",
    "    y.append(\" \".join(s[1:]))\n",
    "    \n",
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eda295d8-ae50-4d7b-9708-163ec6a20d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 'show')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_to_id(word):\n",
    "    return w2v_model.wv.key_to_index[word]\n",
    "\n",
    "def id_to_word(id):\n",
    "    return w2v_model.wv.index_to_key[id]\n",
    "\n",
    "word_to_id('nlp'), id_to_word(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "091e7b1e-245e-4fb7-b561-d35d92c95a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11030, 11030)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_integer_seq(seq):\n",
    "    return [word_to_id(w) for w in seq.split()]\n",
    "\n",
    "# convert text sequences to integer sequences\n",
    "x = [get_integer_seq(i) for i in x]\n",
    "y = [get_integer_seq(i) for i in y]\n",
    "\n",
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6ea852-2c18-436b-8d70-44adfa8c4683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11029, 11029)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length of last sequence, remove if not == seq_len\n",
    "def check_len(seq):\n",
    "    if len(seq[-1]) != seq_len-1:\n",
    "        del seq[-1]\n",
    "    return seq\n",
    "    \n",
    "x = check_len(x)\n",
    "y = check_len(y)\n",
    "\n",
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "197d16c6-4c4e-463b-9776-6fae884cebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to numpy arrays\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb43fb17-104d-468b-884a-2f132d115495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "np.save('data/x.npy', x)\n",
    "np.save('data/y.npy', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
